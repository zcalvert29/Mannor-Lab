{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.glassdoor.com/Reviews/Sherwin-Williams-Reviews-E599.htm\n",
      "scraping 1 companies\n",
      "https://www.glassdoor.com/Reviews/Sherwin-Williams-Reviews-E599.htm?sort.sortType=RD&sort.ascending=true\n",
      "https://www.glassdoor.com/Reviews/Sherwin-Williams-Reviews-E599.htm?sort.sortType=RD&sort.ascending=true: 6726, 673\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'geckodriver' executable needs to be in PATH. \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ed388804fbd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrenturl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: TimedPromise timed out after 300000 ms\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                             stdin=PIPE)\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ed388804fbd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    151\u001b[0m                                                 \u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/usr/local/bin/geckodriver'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                                                 \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                                                 desired_capabilities=caps)   \n\u001b[0m\u001b[0;32m    154\u001b[0m                     \u001b[0mtries\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\firefox\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, firefox_profile, firefox_binary, timeout, capabilities, proxy, executable_path, options, service_log_path, firefox_options, service_args, desired_capabilities, log_path, keep_alive)\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mservice_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 log_path=service_log_path)\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mcapabilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_capabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[0;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[1;32m---> 83\u001b[1;33m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[0;32m     84\u001b[0m                 )\n\u001b[0;32m     85\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: 'geckodriver' executable needs to be in PATH. \n"
     ]
    }
   ],
   "source": [
    "# Do not \"clear all\"\n",
    "# Go to url for page instead of clicking next page\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.firefox.webdriver import FirefoxProfile\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import sys\n",
    "#sys.path.append('/Users/jng2/MendozaResearchTeam Dropbox/MRT/pymodules') # change this to your path\n",
    "import wrangle\n",
    "\n",
    "sourcedat =  \"https://www.glassdoor.com/Reviews/Sherwin-Williams-Reviews-E599.htm\" #'scraped/sp1500_reviews_calvert_6.csv' # either scraped/sp1500_nreviews.csv or a url\n",
    "sort = 'oldest_first' #'newest_first' or 'oldest_first'\n",
    "\n",
    "##############################################################################\n",
    "parsertype = 'html.parser'\n",
    "# Mac desktop: \n",
    "firefoxprofile = r\"C:\\Users\\zcalv\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\brktu7xa.default-1667239152833\"\n",
    "# Mac laptop: /Users/jng2/Library/Application Support/Firefox/Profiles/0ikik30k.default\n",
    "##############################################################################\n",
    "\n",
    "print(sourcedat)\n",
    "\n",
    "os.chdir(r\"C:\\Users\\zcalv\\OneDrive\\Desktop\\Mannor Lab\") # change this to your path\n",
    "\n",
    "logfile = 'scraped/exceptions_' + sort + '.log'\n",
    "   \n",
    "if sourcedat.split('.')[-1] in ['htm','html']:\n",
    "    co_todo = pd.DataFrame({'Glassdoor Review Page':[sourcedat],\n",
    "                            'costub':[sourcedat.split('/')[-1].replace('.html','').replace('.htm','')]})\n",
    "\n",
    "else:   \n",
    "    dat = pd.read_csv(sourcedat)\n",
    "    dat['costub'] = dat['Glassdoor Review Page'].apply(lambda x: str(x).split('/')[-1].replace('.html','').replace('.htm',''))\n",
    "    \n",
    "    scrapedcos =  [p.lstrip('scraped/' + sort + '/').rstrip('.csv') for p in glob.glob('scraped/' + sort + '/*')]\n",
    "    \n",
    "    scrapedcos = pd.DataFrame({'costub': scrapedcos})\n",
    "    \n",
    "    co_todo0 = wrangle.anti_join(dat, scrapedcos, on='costub')\n",
    "    \n",
    "    co_todo0 = co_todo0.reset_index(drop=True)\n",
    "    \n",
    "    co_todo = co_todo0\n",
    "\n",
    "print(f'scraping {co_todo.shape[0]} companies')\n",
    "\n",
    "# HEADLESS FIREFOX\n",
    "profile = FirefoxProfile(firefoxprofile)\n",
    "options = Options()\n",
    "options.headless = True\n",
    "caps = DesiredCapabilities().FIREFOX\n",
    "caps[\"pageLoadStrategy\"] = \"normal\"\n",
    "        \n",
    "for idx, co in co_todo.iterrows():\n",
    "    browser = webdriver.Firefox(profile, \n",
    "                                executable_path=r\"C:\\Users\\zcalv\\geckodriver-v0.28.0-win64\\geckodriver.exe\", \n",
    "                                options=options,\n",
    "                                desired_capabilities=caps)   \n",
    "    time.sleep(randint(1,5))\n",
    "    reviewspage = co['Glassdoor Review Page']   \n",
    "    outfile = 'scraped/' + sort + '/' + co['costub'] + '.csv'\n",
    "    \n",
    "    if os.path.exists(os.getcwd() + '/' + outfile):\n",
    "        df_reviews_all = pd.read_csv(outfile)\n",
    "    else:\n",
    "        df_reviews_all = pd.DataFrame()\n",
    "    \n",
    "    # go straight to reviews page\n",
    "    if sort=='newest_first':\n",
    "        tf = 'false'\n",
    "    elif sort == 'oldest_first':\n",
    "        tf = 'true'\n",
    "    else:\n",
    "        sys.exit('enter a valid sort parameter')\n",
    "    reviewspage_sorted = reviewspage + '?sort.sortType=RD&sort.ascending=' + tf\n",
    "    \n",
    "    print(f'{reviewspage_sorted}')\n",
    "    \n",
    "    browser.get(reviewspage_sorted)\n",
    "              \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # get supposed total number of English reviews to iterate over\n",
    "    try:\n",
    "        WebDriverWait(browser, 30).until(EC.presence_of_element_located((By.XPATH,'//div[@id=\"Footer\"]')))\n",
    "    except TimeoutException:\n",
    "        print(f'landing page did not load')\n",
    "        browser.execute_script(\"document.body.style.transform = 'scale(0.9)'\")\n",
    "        browser.save_screenshot(\"screenshot.png\")\n",
    "        continue \n",
    "\n",
    "    nreviews_str = browser.find_element_by_xpath('//h2[@data-test=\"overallReviewCount\"]/span').text.split('Found ')[-1].split(' ')[0].replace(',','')\n",
    "    \n",
    "    nreviews = int(nreviews_str)\n",
    "    \n",
    "    niter = math.ceil(nreviews/10)\n",
    "    \n",
    "    print(f'{reviewspage_sorted}: {nreviews}, {niter}')       \n",
    "\n",
    "    #df_reviews_all = pd.DataFrame()\n",
    "    \n",
    "    time.sleep(randint(5,10))\n",
    "    \n",
    "    for i in range(niter):\n",
    "        # skip if page already scraped previously\n",
    "        if df_reviews_all.shape[0]>0 and any(df_reviews_all['page']==(i+1)):\n",
    "            continue\n",
    "        \n",
    "        if i==0:\n",
    "            # stay on landing page\n",
    "            pass\n",
    "        else:\n",
    "            # load new page\n",
    "            currenturl = reviewspage_sorted.replace('.htm', '_P'+str(i+1)+'.htm')  \n",
    "            \n",
    "            tries=1\n",
    "            while tries<=3:    \n",
    "                try:\n",
    "                    browser.get(currenturl)\n",
    "                except TimeoutException:\n",
    "                    browser.quit()\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    # HEADLESS FIREFOX\n",
    "                    profile = FirefoxProfile(firefoxprofile)\n",
    "                    options = Options()\n",
    "                    options.headless = True\n",
    "                    caps = DesiredCapabilities().FIREFOX\n",
    "                    caps[\"pageLoadStrategy\"] = \"normal\"\n",
    "                    browser = webdriver.Firefox(profile, \n",
    "                                                executable_path='/usr/local/bin/geckodriver', \n",
    "                                                options=options,\n",
    "                                                desired_capabilities=caps)   \n",
    "                    tries+=1\n",
    "                    time.sleep(1)\n",
    "                else:\n",
    "                    break\n",
    "            if tries>3:\n",
    "                continue\n",
    "                            \n",
    "            try:\n",
    "                WebDriverWait(browser, 30).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"paginationFooter\"]')))\n",
    "            except TimeoutException:\n",
    "                errmsg = f'{currenturl}: did not load'\n",
    "                #print(errmsg)\n",
    "                with open(logfile, 'a') as lf:\n",
    "                    lf.write(f'{date.today()}: {errmsg}\\n')\n",
    "                continue \n",
    "            \n",
    "        \n",
    "        if (round(niter/10)*10)/(i+1) == 2:\n",
    "            print(f'50% done: {date.today()}, {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "            \n",
    "            \n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(browser, 30).until(EC.presence_of_element_located((By.XPATH, \"//div[@id='ReviewsRef']\")))\n",
    "        except TimeoutException:\n",
    "            errmsg = f'{currenturl}: reviews not reached'\n",
    "            #print(errmsg)\n",
    "            with open(logfile, 'a') as lf:\n",
    "                lf.write(f'{date.today()}: {errmsg}\\n')\n",
    "            continue\n",
    "        # else:\n",
    "        #     browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        \n",
    "        continuereading_xpath = \"//div[contains(@class, 'continueReading')]\"\n",
    "        try:\n",
    "            truncreviews = browser.find_elements_by_xpath(continuereading_xpath)\n",
    "        except:\n",
    "            errmsg = f'{currenturl}: Continue Reading xpath is stale'\n",
    "            #print(errmsg)\n",
    "            with open(logfile, 'a') as lf:\n",
    "                lf.write(f'{date.today()}: {errmsg}\\n')\n",
    "            continue\n",
    "        \n",
    "        flag_incomplete = ''\n",
    "        if len(truncreviews)>0:\n",
    "            for trunc in truncreviews:\n",
    "                try:\n",
    "                    WebDriverWait(browser, 30).until(EC.element_to_be_clickable((By.XPATH, continuereading_xpath)))\n",
    "                except:\n",
    "                    errmsg = f'{currenturl}: Continue Reading either timed out or became stale'\n",
    "                    with open(logfile, 'a') as lf:\n",
    "                        lf.write(f'{date.today()}: {errmsg}\\n')\n",
    "                else:\n",
    "                    try:\n",
    "                        trunc.click()\n",
    "                    except:\n",
    "                        flag_incomplete = '1'\n",
    "                    else:\n",
    "                        flag_incomplete = '0'\n",
    "                finally:\n",
    "                    time.sleep(randint(1,5))\n",
    "        \n",
    "        html = browser.page_source.encode('utf-8')\n",
    "\n",
    "        soup = BeautifulSoup(html, parsertype) \n",
    "        \n",
    "        reviews = soup.find('div', {'id':'ReviewsRef'}).find('div', {'id':'ReviewsFeed'}).find('ol', {'class':'empReviews'}).find_all('li', {'id': re.compile('empReview')})\n",
    "        \n",
    "        df_reviews = pd.DataFrame()\n",
    "        \n",
    "        for rvw in reviews:\n",
    "            dct_rvw = dict()\n",
    "            \n",
    "            try:\n",
    "                ratingnumber = rvw.find('span', {'class':re.compile('ratingNumber')}).text\n",
    "            except:\n",
    "                ratingnumber = ''\n",
    "\n",
    "                \n",
    "            dct_hd = dict()\n",
    "            try:\n",
    "                hoverdetails = rvw.find('div', {'class':'tooltipContainer'}).find('div',{'class':'content'}).find('ul').find_all('li')\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                for det in hoverdetails:\n",
    "                    key = re.search(r'[a-zA-Z/&\\s]*', det.text)[0]\n",
    "                    val = ''\n",
    "                    if det.find('div',{'class':'css-xd4dom'}):\n",
    "                        val = '1'\n",
    "                    elif det.find('div',{'class':'css-18v8tui'}):\n",
    "                        val = '2'\n",
    "                    elif det.find('div',{'class':'css-vl2edp'}):\n",
    "                        val = '3'\n",
    "                    elif det.find('div',{'class':'css-1nuumx7'}):\n",
    "                        val = '4'\n",
    "                    elif det.find('div',{'class':'css-s88v13'}):\n",
    "                        val = '5'\n",
    "                    else: #save the class value and decipher stars later (ie 1.5, 2.5, 3.5...)\n",
    "                        try:\n",
    "                            val = det.find('div',{'class':re.compile(r'^css')})['class'][0] \n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                    dct_hd[key] = val\n",
    "            \n",
    "            try:\n",
    "                emptype = rvw.find('span', {'class': re.compile('pt-xsm')}).text\n",
    "            except:\n",
    "                emptype = ''\n",
    "            \n",
    "            try:       \n",
    "                rvwtitle0 = rvw.find('h2', {'class':'mb-xxsm'})\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    rvwtitle = rvwtitle0.text.strip()\n",
    "                except:\n",
    "                    rvwtitle = ''\n",
    "            \n",
    "            try:\n",
    "                rvwlink = rvwtitle0.find('a')['href']\n",
    "            except:\n",
    "                rvwlink = ''       \n",
    "            \n",
    "            try:\n",
    "                empinfo = rvw.find('span', {'class':'common__EiReviewDetailsStyle__newUiJobLine'})\n",
    "            except:\n",
    "                pass            \n",
    "            else:\n",
    "                try:\n",
    "                    rvwdate = re.search(r'^.*20[0-9][0-9]\\b', empinfo.text)[0]\n",
    "                except:\n",
    "                    rvwdate = ''                \n",
    "                try:\n",
    "                    empjob = empinfo.find('span', {'class':'middle common__EiReviewDetailsStyle__newGrey'}).text.replace(rvwdate,'').strip().strip('-').strip()\n",
    "                except:\n",
    "                    empjob = ''                               \n",
    "                try:                          \n",
    "                    if re.search(r'\\xa0in ', empinfo.text):    \n",
    "                        emploc = empinfo.text.split('\\xa0in ')[-1]\n",
    "                    else:\n",
    "                        emploc = ''\n",
    "                except:\n",
    "                    emploc = ''\n",
    "                              \n",
    "            dct_ev = dict()\n",
    "            \n",
    "            try:\n",
    "                empviews = rvw.find('div',{'class':re.compile('reviewBodyCell')}).find_all('div', {'class':'align-items-center'})\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                for ev in empviews:\n",
    "                    empviewtype = ev.text\n",
    "                    empviewval = ''\n",
    "                    if ev.find('span').find('svg', {'class':'css-hcqxoa-svg'}):\n",
    "                        empviewval = 'positive'\n",
    "                    elif ev.find('span').find('svg', {'class':'css-1kiw93k-svg'}):\n",
    "                        empviewval = 'negative'\n",
    "                    elif ev.find('span').find('svg', {'class':'css-1h93d4v-svg'}):\n",
    "                        empviewval = 'neutral'\n",
    "                    elif ev.find('span').find('svg', {'class':'css-10xv9lv-svg'}):\n",
    "                        empviewval = 'blank'\n",
    "                    dct_ev[empviewtype] = empviewval\n",
    "        \n",
    "            try:\n",
    "                rvwpros = rvw.find('span',{'data-test':'pros'}).text.strip()\n",
    "            except:\n",
    "                rvwpros = ''\n",
    "                \n",
    "            try:\n",
    "                rvwcons = rvw.find('span',{'data-test':'cons'}).text.strip()\n",
    "            except:\n",
    "                rvwcons = ''     \n",
    "            \n",
    "            try:\n",
    "                rvwadvm = rvw.find('span',{'data-test':'advice-management'}).text.strip()\n",
    "            except:\n",
    "                rvwadvm = ''  \n",
    "            \n",
    "            dct_rvw['page'] = (i+1)\n",
    "            dct_rvw['rating_overall'] = ratingnumber\n",
    "            dct_rvw['rating_components'] = dct_hd\n",
    "            dct_rvw['employment_status'] = emptype\n",
    "            dct_rvw['review_title'] = rvwtitle\n",
    "            dct_rvw['review_link'] = rvwlink\n",
    "            dct_rvw['review_date'] = rvwdate\n",
    "            dct_rvw['employee_job'] = empjob\n",
    "            dct_rvw['employee_loc'] = emploc\n",
    "            dct_rvw['summary_views'] = dct_ev\n",
    "            dct_rvw['review_pros'] = rvwpros\n",
    "            dct_rvw['review_cons'] = rvwcons\n",
    "            dct_rvw['review_advice_mgmt'] = rvwadvm\n",
    "            dct_rvw['flag_incomplete'] = flag_incomplete\n",
    "            \n",
    "            df_rvw = pd.json_normalize(dct_rvw)\n",
    "            \n",
    "            df_reviews = pd.concat([df_reviews, df_rvw], ignore_index=True)\n",
    "        \n",
    "        del soup, html    \n",
    "        df_reviews_all = pd.concat([df_reviews_all, df_reviews], ignore_index=True)\n",
    "        \n",
    "        df_reviews_all['supposed_n_reviews'] = nreviews_str\n",
    "        \n",
    "        df_reviews_all['Glassdoor Review Page'] = reviewspage\n",
    "\n",
    "        df_reviews_all.to_csv(outfile, index=False)\n",
    "        \n",
    "        time.sleep(1)       \n",
    "\n",
    "    if len(df_reviews_all)>0:\n",
    "        df_reviews_all = wrangle.order_columns(df_reviews_all, ['Glassdoor Review Page','supposed_n_reviews'])\n",
    "        df_reviews_all.to_csv(outfile, index=False)    \n",
    "    browser.close()\n",
    "    print('pausing before moving on to next company')      \n",
    "    #time.sleep(randint(120, 600))  \n",
    "                  \n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
