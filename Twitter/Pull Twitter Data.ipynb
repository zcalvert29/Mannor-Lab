{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "import time\n",
    "import tweepy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Company Data to Extract Twitter Accounts\n",
    "companies = pd.read_excel(\"2022 SP1500 Twitter Handles - Final Deliverable.xlsx\")\n",
    "\n",
    "# Strip @ from Twitter to use with API Call\n",
    "companies['corp_twitter'] = companies['Corporate Twitter Handle'].str[1:]\n",
    "companies['cust_service_twitter'] = companies['Customer Service Twitter Handle'].str[1:]\n",
    "companies['new_ceo_twitter'] = companies['New CEO Twitter Handle'].str[1:]\n",
    "companies['old_ceo_twitter'] = companies['Original Data - CEO Twitter Handle'].str[1:]\n",
    "\n",
    "# Isolate all Twitter accounts we are interested in\n",
    "corp_twitter_list = list(companies[companies['corp_twitter'].notnull()]['corp_twitter'])\n",
    "cust_service_twitter_list = list(companies[companies['cust_service_twitter'].notnull()]['cust_service_twitter'])\n",
    "old_ceo_twitter_list = list(companies[companies['old_ceo_twitter'].notnull()]['old_ceo_twitter'])\n",
    "new_ceo_twitter_list = list(companies[companies['new_ceo_twitter'].notnull()]['new_ceo_twitter'])\n",
    "\n",
    "# API Keys and Bearer Key\n",
    "os.environ['API_KEY'] = # Insert API KEY\n",
    "os.environ['API_SECRET_KEY'] = # INSERT API SECRET KEY\n",
    "os.environ['BEARER_TOKEN'] = # INSERT BEARER TOKEN\n",
    "os.environ['ACCESS_TOKEN'] = # INSERT ACCESS TOKEN\n",
    "os.environ['ACCESS_TOKEN_SECRET'] = # INSERT ACCESS TOKEN SECRET\n",
    "\n",
    "def auth():\n",
    "    '''Pulls the Bearer Token we have stored in the environment for Twitter API Pulls'''\n",
    "    return os.getenv('BEARER_TOKEN')\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    '''Creates the headers necessary for Twitter API Pulls'''\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def create_url(query, start_date, end_date, max_results=500): \n",
    "    '''Creates the URL needed to access the Twitter API, with the data we want to pull out'''\n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/all\" #Change to the endpoint you want to collect data from\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': query,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "                    'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "                    'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    '''Connects to Twitter API endpoint'''\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code == 503:\n",
    "        print('ERROR CODE 503: Server is receiving too many requests. Restart and retry.')\n",
    "        time.sleep(5)\n",
    "        connect_to_endpoint(url, headers, params, next_token = params['next_token'])\n",
    "    elif response.status_code == 400:\n",
    "        print(\"ERROR CODE 400: This account doesn't appear to exist. Check Twitter Handle and try again in the future.\")\n",
    "        return 400\n",
    "    elif response.status_code == 429:\n",
    "        print(\"CODE 429: Usage cap exceeded. Max tweets of 10,000,000 pulled for the month.\")\n",
    "        return 429\n",
    "    elif response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    else:\n",
    "        return response.json()\n",
    "\n",
    "def create_csv(fileName):\n",
    "    '''Creates csv file with contents we want to put in for our Twitter companies'''\n",
    "    if not os.path.exists(fileName):\n",
    "        # Creates file if it doesn't already exist\n",
    "        csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "\n",
    "        #Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "        csvWriter.writerow(['author id', 'created_at', 'geo', 'id','lang', 'like_count', 'quote_count', \n",
    "                        'reply_count','retweet_count', 'tweet_type', 'source','tweet'])\n",
    "        csvFile.close()\n",
    "    else:\n",
    "        print(\"File Already Exists!\")\n",
    "    \n",
    "def append_to_csv(json_response, fileName):\n",
    "    '''Appends data from Twitter API to CSV file that has already been created'''\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in json_response['data']:\n",
    "        \n",
    "        # Isolate Tweet Data\n",
    "        author_id = tweet['author_id']\n",
    "        created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "        tweet_id = tweet['id']\n",
    "        lang = tweet['lang']\n",
    "        retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        reply_count = tweet['public_metrics']['reply_count']\n",
    "        like_count = tweet['public_metrics']['like_count']\n",
    "        quote_count = tweet['public_metrics']['quote_count']\n",
    "        text = tweet['text']\n",
    "        \n",
    "        # Source, if available\n",
    "        if ('source' in tweet):\n",
    "            source = tweet['source']\n",
    "        else:\n",
    "            source = \" \"\n",
    "        #Geolocation, if available\n",
    "        if ('geo' in tweet):   \n",
    "            geo = \" \"\n",
    "        else:\n",
    "            geo = \" \"\n",
    "        \n",
    "        # Kind of Tweet\n",
    "        if ('referenced_tweets' in tweet):\n",
    "            tweet_type = tweet['referenced_tweets'][0]['type']\n",
    "        else:\n",
    "            tweet_type = \"original\"\n",
    "        \n",
    "        # Assemble all data in a list\n",
    "        res = [author_id, created_at, geo, tweet_id, lang, like_count, quote_count, \n",
    "               reply_count, retweet_count, tweet_type, source, text]\n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) \n",
    "    \n",
    "def pull_account_tweets(twitter_handle, account_type, \n",
    "                        start_date='2009-01-01T00:00:00.000Z', end_date='2022-12-31T00:00:00.000Z'):\n",
    "    bearer_token = auth()\n",
    "    headers = create_headers(bearer_token)\n",
    "    query = \"from:\" + str(twitter_handle) + \" lang:en\" # Pulls tweets from that account in the English language\n",
    "    max_results = 500 # 500 is the max amount of tweets we can pull in one query\n",
    "\n",
    "    # Total number of tweets we collected from the loop\n",
    "    total_tweets = 0\n",
    "\n",
    "    fileName = account_type + \" Account Data/\" + str(twitter_handle) + \".csv\" \n",
    "    # FileName is always going to be the twitter handle\n",
    "    create_csv(fileName)\n",
    "    \n",
    "    # Inputs\n",
    "    count = 0 # Counting tweets per time period\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        url = create_url(query, start_date, end_date, max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        if json_response == 400:\n",
    "            break\n",
    "        elif json_response == 429:\n",
    "            break\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call, only runs if there are more tweets in the period\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                append_to_csv(json_response, fileName)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total Tweets Added: \" , total_tweets)\n",
    "                time.sleep(5)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                append_to_csv(json_response, fileName)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total Tweets Added: \", total_tweets)\n",
    "                time.sleep(5)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(5)\n",
    "\n",
    "    print(\"Total number of results: \", total_tweets)\n",
    "    \n",
    "def determine_file_exists(account, account_type):\n",
    "    ''' Function to determine if a csv file exists for the account we want to run. Used to filter accounts \n",
    "        that have already been run'''\n",
    "    if os.path.exists(account_type + \" Account Data/\" + str(account) + \".csv\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def mass_pull_data(account_list, account_type, update_backwards=False, update_forwards=False, forward_year=2022):\n",
    "    # For the future, add way to run for just the past year. This does all tweets or updates for older tweets that weren't\n",
    "    # pulled due to some kind of error. \n",
    "    if account_type == \"Old CEO\":\n",
    "        twitter_handle_column = \"Original Data - CEO Twitter Handle\"\n",
    "    else:\n",
    "        # Ensure account_type is either Corporate, Customer Service, New CEO, or Old CEO\n",
    "        twitter_handle_column = account_type + \" Twitter Handle\"\n",
    "    company_data = (pd.read_excel(\"2022 SP1500 Twitter Handles - Final Deliverable.xlsx\")[['Name', twitter_handle_column]]\n",
    "                        .rename(columns={'Name':'Company', twitter_handle_column:'Twitter Handle'}))\n",
    "    if update_backwards == True:\n",
    "        # Updates backwards, meaning that not all tweets have been pulled for an account.\n",
    "        # This will take the latest tweet pulled and pull all tweets from 2009-01-01 to that tweet's date, updating the \n",
    "        # data file as it goes.\n",
    "        accounts_to_run = account_list\n",
    "        for account in accounts_to_run:\n",
    "            path = Path(account_type + \" Account Data/\"+str(account)+\".csv\")\n",
    "            if path.is_file():\n",
    "                # If the path to that file already exists, check if it's empty\n",
    "                data = pd.read_csv(account_type + \" Account Data/\"+str(account)+\".csv\")\n",
    "                if data.empty:\n",
    "                    # Pull data for the empty file\n",
    "                    print('File Empty. Pulling ' + account + ' Tweets from 2009-01-01 to 2022-12-31')\n",
    "                    pull_account_tweets(account, account_type)\n",
    "                    print('Finished Pulling ' + account + ' Tweets')\n",
    "                else:\n",
    "                    # Isolate last date and pull tweets from beginning to that date\n",
    "                    last_date = data.iloc[-1]['created_at']\n",
    "                    last_date = datetime.datetime.fromisoformat(last_date)\n",
    "                    last_date = last_date.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]+\"Z\"\n",
    "                    print('Pulling ' + account + ' Tweets from 2009-01-01 to ' + str(last_date[:10]))\n",
    "                    pull_account_tweets(account, account_type, end_date=last_date)\n",
    "                    print('Finished Pulling ' + account + ' Tweets')\n",
    "                    #create_summary_data(twitter_handle=account, account_type=account_type, company_data=company_data)\n",
    "                    #print('Updated ' + account + ' Summary Data\\n')\n",
    "            else:\n",
    "                # If the file doesn't exist, it just runs as normal, creating the file and populating with data\n",
    "                print('Pulling ' + account + ' Tweets')\n",
    "                pull_account_tweets(account, account_type)\n",
    "                print('Finished Pulling ' + account + ' Tweets')\n",
    "                #create_summary_data(twitter_handle=account, account_type=account_type, company_data=company_data)\n",
    "                #print('Updated ' + account + ' Summary Data\\n')\n",
    "        print('Completed Running Accounts')\n",
    "        \n",
    "    elif update_forwards == True:\n",
    "        # Updates forwards, meaning it will take the last date in the dataset and a specified year, pulling all tweets\n",
    "        # between those dates.\n",
    "        # Use this when you're updating yearly data (ex: End of 2023, pull all 2023 tweets)\n",
    "        \n",
    "        # WAIT: there's a potential issue if it cuts out in the middle of running this script.\n",
    "        # Since the function pulls from newest to oldest, it could pull Dec 2023 before Jan 2023, error out\n",
    "        # and then it would read Dec 2023 as the newest data, but it'd be missing most of that year and we wouldn't be able\n",
    "        # to pull it.\n",
    "        # Is there a way to pull fowards in time? Start in January and go until Dec? Or maybe a better solution\n",
    "        \n",
    "        # Maybe we check for the last date in the year before, ensure that all data from that year has been collected,\n",
    "        # and then do some kind of similar thing for the year we're trying to pull?\n",
    "        # Ex: Say error happens as it's pulling November data. It doesn't have Jan-Oct. Instead of taking 12-31 as last\n",
    "        # date, we could first see if there's any 2023 data. If so, let's find the earliest date and use that as our end\n",
    "        # date instead of 12-31. In this case, something like 11-10. If there is no 2023 data, the code functions as normal\n",
    "        \n",
    "        accounts_to_run = account_list\n",
    "        for account in accounts_to_run:\n",
    "            path = Path(account_type + \" Account Data/\"+str(account)+\".csv\")\n",
    "            if path.is_file():\n",
    "                # If the path to that file already exists, check if it's empty\n",
    "                data = pd.read_csv(account_type + \" Account Data/\"+str(account)+\".csv\")\n",
    "                if data.empty:\n",
    "                    # Pull data for the empty file\n",
    "                    print('File Empty. Pulling ' + account + ' Tweets from 2009-01-01 to 2022-12-31')\n",
    "                    pull_account_tweets(account, account_type)\n",
    "                    print('Finished Pulling ' + account + ' Tweets')\n",
    "                else:\n",
    "                    # Isolate latest date in the set, set that as our new start_date, and use defined end_date\n",
    "                    # as our end_date, pulling all tweets in between that time\n",
    "                    data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "                    data = data.sort_values('created_at', ascending=False)\n",
    "                    start_date = data['created_at'][0]\n",
    "                    start_date = start_date.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]+\"Z\"\n",
    "                    end_date = str(forward_year) + \"-12-31T00:00:00.000Z\"\n",
    "                    print('Pulling ' + account + ' Tweets from ' + str(start_date[:10]) + ' to ' + str(end_date[:10]))\n",
    "                    pull_account_tweets(account, account_type, start_date=start_date, end_date=end_date)\n",
    "                    print('Finished Pulling ' + account + ' Tweets')\n",
    "            else:\n",
    "                # If the file doesn't exist, it just runs as normal, creating the file and populating with data\n",
    "                print('Pulling ' + account + ' Tweets')\n",
    "                pull_account_tweets(account, account_type)\n",
    "                print('Finished Pulling ' + account + ' Tweets')\n",
    "                #create_summary_data(twitter_handle=account, account_type=account_type, company_data=company_data)\n",
    "                #print('Updated ' + account + ' Summary Data\\n')\n",
    "    else:\n",
    "        # Pulls all data for accounts we pass in a list to it\n",
    "        # Filter out companies we've already run to speed up process.\n",
    "        accounts_to_run = [account for account in account_list if not determine_file_exists(account, account_type)]\n",
    "        for account in accounts_to_run:\n",
    "            print('Pulling ' + account + ' Tweets')\n",
    "            pull_account_tweets(account, account_type) # Pulls tweets until there's no more or it errors out\n",
    "            print('Finished Pulling ' + account + ' Tweets')\n",
    "            create_summary_data(twitter_handle=account, account_type=account_type, company_data=company_data)\n",
    "            print('Updated ' + account + ' Summary Data\\n')\n",
    "    print('Completed Updating Account Data')\n",
    "        \n",
    "def create_summary_data(twitter_handle, account_type, company_data):\n",
    "    # Creates Yearly Summary\n",
    "    data = pd.read_csv(account_type + \" Account Data/\"+str(twitter_handle)+\".csv\")\n",
    "    data['created_at'] = pd.to_datetime(data['created_at'], format = \"%Y-%m-%d\")\n",
    "    data['year'] = data['created_at'].dt.year\n",
    "    tweet_data = (data.groupby(['year', 'tweet_type']).size().reset_index(name='counts')\n",
    "     .pivot(index='year', columns='tweet_type',values='counts').fillna(0).reset_index())\n",
    "    types_of_tweets = ['original', 'quoted', 'replied_to', 'retweeted']\n",
    "    for tweet in types_of_tweets:\n",
    "        if tweet not in tweet_data.columns:\n",
    "            tweet_data[tweet] = 0\n",
    "    tweet_data = tweet_data.rename(columns={'year':'Year', 'original': 'Original Tweets', 'quoted':'Quote Tweets', \n",
    "                      'replied_to':'Reply Tweets', 'retweeted':'Retweets'})\n",
    "    tweet_summary = (data[data['tweet_type'] == \"original\"].groupby('year')\n",
    "     .agg({'like_count':'sum', 'retweet_count':'sum', 'reply_count':'sum', 'quote_count': 'sum'}).fillna(0).reset_index()\n",
    "     .rename(columns={'year':'Year', 'like_count':'Original Tweet Likes', 'retweet_count': 'Original Tweet Retweets', \n",
    "                      'reply_count':'Original Tweet Replies', 'quote_count': 'Original Tweet Quotes'})\n",
    "    )\n",
    "\n",
    "    tweet_data = tweet_data.merge(tweet_summary, on='Year')\n",
    "    tweet_data['Twitter Handle'] = \"@\" + str(twitter_handle)\n",
    "    tweet_data['Account Type'] = str(account_type)\n",
    "    tweet_data = (tweet_data.merge(company_data, on='Twitter Handle', how='left')\n",
    "                  .drop_duplicates(subset=['Year', 'Twitter Handle'], keep='first'))\n",
    "    tweet_data = tweet_data[['Company', 'Account Type', 'Twitter Handle', 'Year', 'Original Tweets', 'Retweets', 'Reply Tweets',\n",
    "                            'Quote Tweets', 'Original Tweet Retweets', 'Original Tweet Likes', 'Original Tweet Replies',\n",
    "                            'Original Tweet Quotes']]\n",
    "    #tweet_data.to_csv(\"./Summary Data/Yearly Summary.csv\", mode='a', header=False)\n",
    "    \n",
    "    # Creates Overall Summary\n",
    "    api_key = os.getenv('API_KEY')\n",
    "    api_secret_key = os.getenv('API_SECRET_KEY')\n",
    "    access_token = os.getenv('ACCESS_TOKEN')\n",
    "    access_token_secret = os.getenv('ACCESS_TOKEN_SECRET')\n",
    "    \n",
    "    summary = pd.DataFrame(data[data['tweet_type'] == 'original'].agg({'like_count': 'sum', 'quote_count': 'sum', \n",
    "                                            'reply_count': 'sum', 'retweet_count': 'sum'})).transpose()\n",
    "    summary['Twitter Handle'] = \"@\"+twitter_handle\n",
    "    tweet_summary = pd.DataFrame(data.groupby('tweet_type').size()).transpose().rename_axis(None, axis=1)\n",
    "    for tweet in types_of_tweets:\n",
    "        if tweet not in tweet_summary.columns:\n",
    "            tweet_summary[tweet] = 0\n",
    "    tweet_summary['Twitter Handle'] = \"@\"+twitter_handle\n",
    "    summary = summary.merge(tweet_summary, on='Twitter Handle')\n",
    "\n",
    "    auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    try:\n",
    "        user = api.get_user(screen_name = twitter_handle)\n",
    "    except tweepy.errors.NotFound:\n",
    "        print(f\"OOPS! User {twitter_handle} not found. Account no longer exists. Try  different method\")\n",
    "        return\n",
    "    except tweepy.errors.Forbidden:\n",
    "        print(f\"OOPS! User {twitter_handle} has been suspended.\")\n",
    "        return\n",
    "    summary['Account Followers'] = user.followers_count\n",
    "    summary['Account Following'] = user.friends_count\n",
    "    summary['Account Likes'] = user.favourites_count\n",
    "    summary['Account Public Lists'] = user.listed_count\n",
    "    summary['Account Creation Date'] = user.created_at\n",
    "    summary = summary.rename(columns = {'like_count': 'Original Tweet Likes', 'quote_count': 'Original Tweet Quotes', \n",
    "                                        'reply_count': 'Original Tweet Replies', 'retweet_count': 'Original Tweet Retweets',\n",
    "                                        'original': 'Original Tweets', 'quoted': 'Quote Tweets', 'replied_to': 'Reply Tweets',\n",
    "                                        'retweeted': 'Retweets'\n",
    "                                       })\n",
    "    summary['Account Type'] = account_type\n",
    "    summary = (summary.merge(company_data, left_on='Twitter Handle', right_on='Twitter Handle', how='left')\n",
    "     .drop_duplicates(subset='Twitter Handle', keep='first'))\n",
    "    summary = summary[['Company', 'Account Type', 'Twitter Handle', 'Account Creation Date', 'Account Followers', 'Account Following',\n",
    "        'Account Likes', 'Account Public Lists', 'Original Tweets', 'Retweets', 'Reply Tweets', 'Quote Tweets', \n",
    "        'Original Tweet Retweets', 'Original Tweet Likes', 'Original Tweet Replies', 'Original Tweet Quotes']]\n",
    "    #summary.to_csv(\"./Summary Data/Overall Summary.csv\", mode='a', header=False)\n",
    "    \n",
    "    total = tweet_data.merge(summary, on=['Company', 'Account Type', 'Twitter Handle'], suffixes=[' Year', ' Total'])\n",
    "    total.to_csv(\"./Summary Data/Tweets Summary.csv\", mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling Apple Tweets from 2009-01-01 to 2016-09-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Apple Tweets\n",
      "Pulling Microsoft Tweets from 2009-01-01 to 2009-09-21\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Microsoft Tweets\n",
      "Pulling exxonmobil Tweets from 2009-01-01 to 2009-10-21\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling exxonmobil Tweets\n",
      "Pulling JNJNews Tweets from 2009-01-01 to 2009-02-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling JNJNews Tweets\n",
      "Pulling generalelectric Tweets from 2009-01-01 to 2011-04-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling generalelectric Tweets\n",
      "Pulling amazon Tweets from 2009-01-01 to 2009-02-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling amazon Tweets\n",
      "Pulling facebook Tweets from 2009-01-01 to 2020-01-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling facebook Tweets\n",
      "Pulling ATT Tweets from 2009-01-01 to 2009-01-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ATT Tweets\n",
      "Pulling jpmorgan Tweets from 2009-01-01 to 2013-06-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling jpmorgan Tweets\n",
      "Pulling WellsFargo Tweets from 2009-01-01 to 2010-09-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WellsFargo Tweets\n",
      "Pulling ProcterGamble Tweets from 2009-01-01 to 2009-03-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ProcterGamble Tweets\n",
      "Pulling google Tweets from 2009-01-01 to 2009-02-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling google Tweets\n",
      "Pulling google Tweets from 2009-01-01 to 2009-02-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling google Tweets\n",
      "Pulling pfizer Tweets from 2009-01-01 to 2009-07-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling pfizer Tweets\n",
      "Pulling verizon Tweets from 2009-01-01 to 2009-08-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  98\n",
      "Total Tweets Added:  98\n",
      "Total number of results:  98\n",
      "Finished Pulling verizon Tweets\n",
      "Pulling Chevron Tweets from 2009-01-01 to 2009-02-16\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Chevron Tweets\n",
      "Pulling CocaColaCo Tweets from 2009-01-01 to 2010-10-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CocaColaCo Tweets\n",
      "Pulling HomeDepot Tweets from 2009-01-01 to 2009-01-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling HomeDepot Tweets\n",
      "Pulling Merck Tweets from 2009-01-01 to 2011-09-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Merck Tweets\n",
      "Pulling InsidePMI Tweets from 2009-01-01 to 2013-09-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling InsidePMI Tweets\n",
      "Pulling Visa Tweets from 2009-01-01 to 2012-05-07\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Visa Tweets\n",
      "Pulling comcast Tweets from 2009-01-01 to 2009-11-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling comcast Tweets\n",
      "Pulling intel Tweets from 2009-01-01 to 2009-03-03\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling intel Tweets\n",
      "Pulling PepsiCo Tweets from 2009-01-01 to 2009-02-24\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PepsiCo Tweets\n",
      "Pulling Disney Tweets from 2009-01-01 to 2010-12-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Disney Tweets\n",
      "Pulling Cisco Tweets from 2009-01-01 to 2009-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Cisco Tweets\n",
      "Pulling BankofAmerica Tweets from 2009-01-01 to 2010-12-03\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling BankofAmerica Tweets\n",
      "Pulling IBM Tweets from 2009-01-01 to 2011-05-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling IBM Tweets\n",
      "Pulling UnitedHealthGrp Tweets from 2009-01-01 to 2014-07-17\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling UnitedHealthGrp Tweets\n",
      "Pulling Citi Tweets from 2009-01-01 to 2010-01-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Citi Tweets\n",
      "Pulling AltriaNews Tweets from 2009-01-01 to 2011-04-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AltriaNews Tweets\n",
      "Pulling Oracle Tweets from 2009-01-01 to 2009-01-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Oracle Tweets\n",
      "Pulling bmsnews Tweets from 2009-01-01 to 2010-03-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling bmsnews Tweets\n",
      "Pulling Medtronic Tweets from 2009-01-01 to 2009-07-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Medtronic Tweets\n",
      "Pulling Amgen Tweets from 2009-01-01 to 2009-05-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Amgen Tweets\n",
      "Pulling GileadSciences Tweets from 2009-01-01 to 2012-03-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling GileadSciences Tweets\n",
      "Pulling Walmart Tweets from 2009-01-01 to 2009-01-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Walmart Tweets\n",
      "Pulling McDonaldsCorp Tweets from 2009-01-01 to 2010-03-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling McDonaldsCorp Tweets\n",
      "Pulling CVSHealth Tweets from 2009-01-01 to 2010-08-25\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CVSHealth Tweets\n",
      "Pulling 3M Tweets from 2009-01-01 to 2014-02-04\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling 3M Tweets\n",
      "Pulling abbvie Tweets from 2009-01-01 to 2013-01-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling abbvie Tweets\n",
      "Pulling abbvie Tweets from 2009-01-01 to 2013-01-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling abbvie Tweets\n",
      "Pulling MasterCard Tweets from 2009-01-01 to 2010-02-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MasterCard Tweets\n",
      "Pulling Honeywell Tweets from 2009-01-01 to 2009-08-11\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Honeywell Tweets\n",
      "Pulling bmsnews Tweets from 2009-01-01 to 2010-03-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling bmsnews Tweets\n",
      "Pulling Boeing Tweets from 2009-01-01 to 2010-03-25\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Boeing Tweets\n",
      "Pulling Qualcomm Tweets from 2009-01-01 to 2009-10-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Qualcomm Tweets\n",
      "Pulling Starbucks Tweets from 2009-01-01 to 2009-01-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Starbucks Tweets\n",
      "Pulling UTC Tweets from 2009-01-01 to 2011-06-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling UTC Tweets\n",
      "Pulling UnionPacific Tweets from 2009-01-01 to 2009-06-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling UnionPacific Tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling Accenture Tweets from 2009-01-01 to 2009-01-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Accenture Tweets\n",
      "Pulling Nike Tweets from 2009-01-01 to 2011-12-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Nike Tweets\n",
      "Pulling UPS Tweets from 2009-01-01 to 2010-07-21\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling UPS Tweets\n",
      "Pulling LillyPad Tweets from 2009-01-01 to 2010-09-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling LillyPad Tweets\n",
      "Pulling Lowes Tweets from 2009-01-01 to 2009-01-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Lowes Tweets\n",
      "Pulling MDLZ Tweets from 2009-01-01 to 2014-06-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MDLZ Tweets\n",
      "Pulling usbank Tweets from 2009-01-01 to 2011-05-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling usbank Tweets\n",
      "Pulling WBA_Global Tweets from 2009-01-01 to 2020-04-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WBA_Global Tweets\n",
      "Pulling priceline Tweets from 2009-01-01 to 2009-02-11\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling priceline Tweets\n",
      "Pulling CP_News Tweets from 2009-01-01 to 2011-01-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CP_News Tweets\n",
      "Pulling AIGinsurance Tweets from 2009-01-01 to 2011-03-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AIGinsurance Tweets\n",
      "Pulling LockheedMartin Tweets from 2009-01-01 to 2009-07-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling LockheedMartin Tweets\n",
      "Pulling TXInstruments Tweets from 2009-01-01 to 2009-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling TXInstruments Tweets\n",
      "Pulling SimonPropertyGp Tweets from 2009-01-01 to 2011-05-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SimonPropertyGp Tweets\n",
      "Pulling thermofisher Tweets from 2009-01-01 to 2009-09-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling thermofisher Tweets\n",
      "Pulling Broadcom Tweets from 2009-01-01 to 2011-07-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Broadcom Tweets\n",
      "Pulling GoldmanSachs Tweets from 2009-01-01 to 2012-05-24\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling GoldmanSachs Tweets\n",
      "Pulling DanaherCorp Tweets from 2009-01-01 to 2022-07-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DanaherCorp Tweets\n",
      "Pulling DowNewsroom Tweets from 2009-01-01 to 2010-11-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DowNewsroom Tweets\n",
      "Pulling wbd Tweets from 2009-01-01 to 2009-03-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling wbd Tweets\n",
      "Pulling DuPont_News Tweets from 2009-01-01 to 2009-03-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DuPont_News Tweets\n",
      "Pulling Chubb Tweets from 2009-01-01 to 2009-07-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Chubb Tweets\n",
      "Pulling WeAreOxy Tweets from 2009-01-01 to 2013-10-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WeAreOxy Tweets\n",
      "Pulling conocophillips Tweets from 2009-01-01 to 2009-05-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling conocophillips Tweets\n",
      "Pulling AbbottNews Tweets from 2009-01-01 to 2011-10-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AbbottNews Tweets\n",
      "Pulling nexteraenergy Tweets from 2009-01-01 to 2014-12-03\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling nexteraenergy Tweets\n",
      "Pulling DukeEnergy Tweets from 2009-01-01 to 2009-10-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DukeEnergy Tweets\n",
      "Pulling biogen Tweets from 2009-01-01 to 2014-03-04\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling biogen Tweets\n",
      "File Empty. Pulling DellEMC Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DellEMC Tweets\n",
      "Pulling AmericanExpress Tweets from 2009-01-01 to 2010-04-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  500\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  500\n",
      "Finished Pulling AmericanExpress Tweets\n",
      "Pulling salesforce Tweets from 2009-01-01 to 2009-05-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling salesforce Tweets\n",
      "Pulling tjmaxx Tweets from 2009-01-01 to 2009-01-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling tjmaxx Tweets\n",
      "Pulling Ford Tweets from 2009-01-01 to 2009-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Ford Tweets\n",
      "Pulling KraftHeinzCo Tweets from 2009-01-01 to 2011-05-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling KraftHeinzCo Tweets\n",
      "Pulling Adobe Tweets from 2009-01-01 to 2010-05-17\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  499\n",
      "Total Tweets Added:  499\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  499\n",
      "Finished Pulling Adobe Tweets\n",
      "Pulling ExpressScripts Tweets from 2009-01-01 to 2011-09-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ExpressScripts Tweets\n",
      "Pulling Bayer Tweets from 2009-01-01 to 2013-08-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Bayer Tweets\n",
      "Pulling MetLife Tweets from 2009-01-01 to 2013-01-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MetLife Tweets\n",
      "Pulling KCCorp Tweets from 2009-01-01 to 2011-01-04\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling KCCorp Tweets\n",
      "Pulling SouthernCompany Tweets from 2009-01-01 to 2009-04-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SouthernCompany Tweets\n",
      "File Empty. Pulling AmericanTowerUS Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AmericanTowerUS Tweets\n",
      "Pulling blackrock Tweets from 2009-01-01 to 2011-03-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling blackrock Tweets\n",
      "Pulling CaterpillarInc Tweets from 2009-01-01 to 2009-01-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CaterpillarInc Tweets\n",
      "Pulling BNYMellon Tweets from 2009-01-01 to 2010-07-16\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling BNYMellon Tweets\n",
      "Pulling PNCBank Tweets from 2009-01-01 to 2009-05-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PNCBank Tweets\n",
      "Pulling DominionEnergy Tweets from 2009-01-01 to 2010-01-17\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DominionEnergy Tweets\n",
      "Pulling McKesson Tweets from 2009-01-01 to 2010-05-27\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling McKesson Tweets\n",
      "Pulling Aetna Tweets from 2009-01-01 to 2012-02-17\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Aetna Tweets\n",
      "Pulling RAI_News Tweets from 2009-01-01 to 2012-02-07\n",
      "File Already Exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling RAI_News Tweets\n",
      "Pulling FedEx Tweets from 2009-01-01 to 2010-06-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  102\n",
      "Total Tweets Added:  102\n",
      "Total number of results:  102\n",
      "Finished Pulling FedEx Tweets\n",
      "Pulling netflix Tweets from 2009-01-01 to 2009-01-07\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling netflix Tweets\n",
      "Pulling GDMS Tweets from 2009-01-01 to 2012-09-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling GDMS Tweets\n",
      "Pulling PayPal Tweets from 2009-01-01 to 2009-05-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PayPal Tweets\n",
      "Pulling GM Tweets from 2009-01-01 to 2009-01-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling GM Tweets\n",
      "Pulling RaytheonTech Tweets from 2009-01-01 to 2009-06-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling RaytheonTech Tweets\n",
      "Pulling Target Tweets from 2009-01-01 to 2009-11-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Target Tweets\n",
      "Pulling ADP Tweets from 2009-01-01 to 2009-02-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ADP Tweets\n",
      "Pulling MorganStanley Tweets from 2009-01-01 to 2012-04-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MorganStanley Tweets\n",
      "Pulling northropgrumman Tweets from 2009-01-01 to 2009-01-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling northropgrumman Tweets\n",
      "Pulling Halliburton Tweets from 2009-01-01 to 2011-04-28\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Halliburton Tweets\n",
      "Pulling GeneralMills Tweets from 2009-01-01 to 2011-05-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling GeneralMills Tweets\n",
      "Pulling Phillips66Co Tweets from 2009-01-01 to 2012-05-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Phillips66Co Tweets\n",
      "Pulling CapitalOne Tweets from 2009-01-01 to 2012-06-25\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CapitalOne Tweets\n",
      "Pulling Cognizant Tweets from 2009-01-01 to 2009-08-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Cognizant Tweets\n",
      "Pulling PublicStorage Tweets from 2009-01-01 to 2010-08-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PublicStorage Tweets\n",
      "Pulling StrykerEndo Tweets from 2009-01-01 to 2012-03-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling StrykerEndo Tweets\n",
      "Pulling BDandCo Tweets from 2009-01-01 to 2009-12-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling BDandCo Tweets\n",
      "Pulling kroger Tweets from 2009-01-01 to 2010-02-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling kroger Tweets\n",
      "File Empty. Pulling ITWInc Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ITWInc Tweets\n",
      "Pulling CharlesSchwab Tweets from 2009-01-01 to 2010-05-17\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CharlesSchwab Tweets\n",
      "File Empty. Pulling AnthemInc Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AnthemInc Tweets\n",
      "File Empty. Pulling MMC_Global Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MMC_Global Tweets\n",
      "Pulling Emerson_News Tweets from 2009-01-01 to 2009-08-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Emerson_News Tweets\n",
      "Pulling yumbrands Tweets from 2009-01-01 to 2009-03-28\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling yumbrands Tweets\n",
      "Pulling Travelers Tweets from 2009-01-01 to 2009-01-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Travelers Tweets\n",
      "Pulling HPE Tweets from 2009-01-01 to 2010-11-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling HPE Tweets\n",
      "Pulling Prudential Tweets from 2009-01-01 to 2013-03-27\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Prudential Tweets\n",
      "Pulling Kinder_Morgan Tweets from 2009-01-01 to 2010-03-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Kinder_Morgan Tweets\n",
      "Pulling Cigna Tweets from 2009-01-01 to 2009-05-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Cigna Tweets\n",
      "Pulling Delta Tweets from 2009-01-01 to 2009-06-11\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Delta Tweets\n",
      "Pulling AEPnews Tweets from 2009-01-01 to 2009-09-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AEPnews Tweets\n",
      "Pulling 21CF Tweets from 2009-01-01 to 2013-06-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling 21CF Tweets\n",
      "Pulling Yahoo Tweets from 2009-01-01 to 2009-02-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Yahoo Tweets\n",
      "Pulling Exelon Tweets from 2009-01-01 to 2014-01-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Exelon Tweets\n",
      "Pulling Ecolab Tweets from 2009-01-01 to 2011-02-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Ecolab Tweets\n",
      "Pulling CMEGroup Tweets from 2009-01-01 to 2009-01-03\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CMEGroup Tweets\n",
      "Pulling CrownCastle Tweets from 2009-01-01 to 2017-12-04\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CrownCastle Tweets\n",
      "Pulling bostonsci Tweets from 2009-01-01 to 2012-05-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling bostonsci Tweets\n",
      "Pulling ICE_Markets Tweets from 2009-01-01 to 2009-03-24\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ICE_Markets Tweets\n",
      "Pulling AlexionPharma Tweets from 2009-01-01 to 2017-11-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AlexionPharma Tweets\n",
      "Pulling PGE4Me Tweets from 2009-01-01 to 2010-02-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  499\n",
      "Total Tweets Added:  499\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  499\n",
      "Finished Pulling PGE4Me Tweets\n",
      "Pulling regeneron Tweets from 2009-01-01 to 2014-11-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling regeneron Tweets\n",
      "Pulling Aon_plc Tweets from 2009-01-01 to 2009-03-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Aon_plc Tweets\n",
      "Pulling PPG Tweets from 2009-01-01 to 2009-04-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PPG Tweets\n",
      "Pulling TruistNews Tweets from 2009-01-01 to 2020-01-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling TruistNews Tweets\n",
      "Pulling Aflac Tweets from 2009-01-01 to 2009-04-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Aflac Tweets\n",
      "Pulling SPGlobal Tweets from 2009-01-01 to 2010-03-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SPGlobal Tweets\n",
      "Pulling johnsoncontrols Tweets from 2009-01-01 to 2013-04-23\n",
      "File Already Exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling johnsoncontrols Tweets\n",
      "Pulling eatoncorp Tweets from 2009-01-01 to 2009-01-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling eatoncorp Tweets\n",
      "Pulling airproducts Tweets from 2009-01-01 to 2010-01-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling airproducts Tweets\n",
      "Pulling SouthwestAir Tweets from 2009-01-01 to 2009-01-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SouthwestAir Tweets\n",
      "Pulling Humana Tweets from 2009-01-01 to 2011-10-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Humana Tweets\n",
      "Pulling WeAreOxy Tweets from 2009-01-01 to 2013-10-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WeAreOxy Tweets\n",
      "Pulling LyondellBasell Tweets from 2009-01-01 to 2010-04-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling LyondellBasell Tweets\n",
      "File Empty. Pulling semiwestapplied Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling semiwestapplied Tweets\n",
      "Pulling Intuit Tweets from 2009-01-01 to 2009-01-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Intuit Tweets\n",
      "Pulling cbrands Tweets from 2009-01-01 to 2017-08-21\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling cbrands Tweets\n",
      "Pulling PXDtweets Tweets from 2009-01-01 to 2014-05-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PXDtweets Tweets\n",
      "Pulling DollarGeneral Tweets from 2009-01-01 to 2009-10-21\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DollarGeneral Tweets\n",
      "Pulling PPLCorp Tweets from 2009-01-01 to 2014-05-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PPLCorp Tweets\n",
      "Pulling eBay Tweets from 2009-01-01 to 2009-02-16\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling eBay Tweets\n",
      "Pulling Synchrony Tweets from 2009-01-01 to 2009-01-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Synchrony Tweets\n",
      "Pulling Prologis Tweets from 2009-01-01 to 2010-02-11\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Prologis Tweets\n",
      "Pulling cardinalhealth Tweets from 2009-01-01 to 2011-04-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling cardinalhealth Tweets\n",
      "Pulling ADMupdates Tweets from 2009-01-01 to 2011-08-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ADMupdates Tweets\n",
      "Pulling CSX Tweets from 2009-01-01 to 2009-05-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CSX Tweets\n",
      "Pulling JohnDeere Tweets from 2009-01-01 to 2009-10-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling JohnDeere Tweets\n",
      "Pulling WasteManagement Tweets from 2009-01-01 to 2010-02-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WasteManagement Tweets\n",
      "File Empty. Pulling SempraEnergy Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SempraEnergy Tweets\n",
      "Pulling Sysco Tweets from 2009-01-01 to 2013-01-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Sysco Tweets\n",
      "Pulling Equinix Tweets from 2009-01-01 to 2009-11-04\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Equinix Tweets\n",
      "Pulling Allstate Tweets from 2009-01-01 to 2009-01-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Allstate Tweets\n",
      "Pulling Welltower Tweets from 2009-01-01 to 2016-01-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Welltower Tweets\n",
      "Pulling nscorp Tweets from 2009-01-01 to 2010-02-16\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling nscorp Tweets\n",
      "Pulling oreillyauto Tweets from 2009-01-01 to 2013-08-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling oreillyauto Tweets\n",
      "File Empty. Pulling ValeroEnergy_ Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ValeroEnergy_ Tweets\n",
      "Pulling HCAhealthcare Tweets from 2009-01-01 to 2009-08-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling HCAhealthcare Tweets\n",
      "Pulling baxter_intl Tweets from 2009-01-01 to 2010-02-03\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling baxter_intl Tweets\n",
      "Pulling IntuitiveSurg Tweets from 2009-01-01 to 2012-08-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling IntuitiveSurg Tweets\n",
      "Pulling nvidia Tweets from 2009-01-01 to 2009-07-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling nvidia Tweets\n",
      "Pulling StateStreet Tweets from 2009-01-01 to 2011-07-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling StateStreet Tweets\n",
      "Pulling edisonintl Tweets from 2009-01-01 to 2011-07-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling edisonintl Tweets\n",
      "Pulling Fiserv Tweets from 2009-01-01 to 2009-09-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Fiserv Tweets\n",
      "Pulling HP Tweets from 2009-01-01 to 2009-01-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling HP Tweets\n",
      "Pulling EA Tweets from 2009-01-01 to 2009-01-07\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling EA Tweets\n",
      "Pulling Discover Tweets from 2009-01-01 to 2009-01-07\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Discover Tweets\n",
      "Pulling EquityRes Tweets from 2009-01-01 to 2011-08-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling EquityRes Tweets\n",
      "Pulling Corning Tweets from 2009-01-01 to 2010-01-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Corning Tweets\n",
      "Pulling AvalonBay Tweets from 2009-01-01 to 2009-03-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AvalonBay Tweets\n",
      "Pulling TEConnectivity Tweets from 2009-01-01 to 2009-05-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling TEConnectivity Tweets\n",
      "Pulling VentasREIT Tweets from 2009-01-01 to 2021-02-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling VentasREIT Tweets\n",
      "Pulling SherwinWilliams Tweets from 2009-01-01 to 2010-02-04\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SherwinWilliams Tweets\n",
      "Pulling autozone Tweets from 2009-01-01 to 2011-07-28\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling autozone Tweets\n",
      "Pulling VertexPharma Tweets from 2009-01-01 to 2010-01-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling VertexPharma Tweets\n",
      "Pulling Weyerhaeuser Tweets from 2009-01-01 to 2011-09-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Weyerhaeuser Tweets\n",
      "Pulling SpectraEnergy Tweets from 2009-01-01 to 2010-05-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SpectraEnergy Tweets\n",
      "Pulling PSEGNews Tweets from 2009-01-01 to 2011-01-13\n",
      "File Already Exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PSEGNews Tweets\n",
      "Pulling ConEdison Tweets from 2009-01-01 to 2012-06-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ConEdison Tweets\n",
      "Pulling newell_brands Tweets from 2009-01-01 to 2012-04-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling newell_brands Tweets\n",
      "Pulling CBSTweet Tweets from 2009-01-01 to 2009-03-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CBSTweet Tweets\n",
      "Pulling SJM_Media Tweets from 2009-01-01 to 2013-10-07\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SJM_Media Tweets\n",
      "Pulling Zoetis Tweets from 2009-01-01 to 2013-02-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Zoetis Tweets\n",
      "Pulling EdwardsLifesci Tweets from 2009-01-01 to 2015-03-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling EdwardsLifesci Tweets\n",
      "Pulling Ross_Stores Tweets from 2009-01-01 to 2015-11-16\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Ross_Stores Tweets\n",
      "Pulling MonsterEnergy Tweets from 2009-01-01 to 2009-08-28\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MonsterEnergy Tweets\n",
      "Pulling TruistNews Tweets from 2009-01-01 to 2020-01-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling TruistNews Tweets\n",
      "Pulling xcelenergy Tweets from 2009-01-01 to 2010-03-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling xcelenergy Tweets\n",
      "Pulling CarnivalPLC Tweets from 2009-01-01 to 2014-11-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CarnivalPLC Tweets\n",
      "Pulling DollarTree Tweets from 2009-01-01 to 2009-12-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DollarTree Tweets\n",
      "Pulling VFCorp Tweets from 2009-01-01 to 2017-01-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling VFCorp Tweets\n",
      "Pulling zimmerbiomet Tweets from 2009-01-01 to 2011-05-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling zimmerbiomet Tweets\n",
      "Pulling APA_Corp Tweets from 2009-01-01 to 2009-07-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling APA_Corp Tweets\n",
      "Pulling illumina Tweets from 2009-01-01 to 2009-06-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling illumina Tweets\n",
      "Pulling bakerhughesco Tweets from 2009-01-01 to 2009-09-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling bakerhughesco Tweets\n",
      "Pulling FISGlobal Tweets from 2009-01-01 to 2013-11-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling FISGlobal Tweets\n",
      "Pulling EsteeLauder Tweets from 2009-01-01 to 2011-07-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling EsteeLauder Tweets\n",
      "Pulling ConagraBrands Tweets from 2009-01-01 to 2010-03-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ConagraBrands Tweets\n",
      "Pulling Omnicom Tweets from 2009-01-01 to 2013-08-21\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Omnicom Tweets\n",
      "Pulling AmericanAir Tweets from 2009-01-01 to 2009-04-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AmericanAir Tweets\n",
      "Pulling Nielsen Tweets from 2009-01-01 to 2009-01-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Nielsen Tweets\n",
      "Pulling SustainableBXP Tweets from 2009-01-01 to 2017-10-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling SustainableBXP Tweets\n",
      "Pulling PACCARFinancial Tweets from 2009-01-01 to 2012-01-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PACCARFinancial Tweets\n",
      "Pulling WECEnergyGroup Tweets from 2009-01-01 to 2015-06-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WECEnergyGroup Tweets\n",
      "Pulling KelloggCompany Tweets from 2009-01-01 to 2012-05-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling KelloggCompany Tweets\n",
      "Pulling MarathonPetroCo Tweets from 2009-01-01 to 2014-11-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MarathonPetroCo Tweets\n",
      "Pulling ATVI_AB Tweets from 2009-01-01 to 2016-07-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ATVI_AB Tweets\n",
      "Pulling Cummins Tweets from 2009-01-01 to 2010-07-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Cummins Tweets\n",
      "Pulling Progressive Tweets from 2009-01-01 to 2009-03-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Progressive Tweets\n",
      "File Empty. Pulling DelphiAuto Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DelphiAuto Tweets\n",
      "Pulling DevonEnergy Tweets from 2009-01-01 to 2016-05-03\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DevonEnergy Tweets\n",
      "Pulling MolsonCoors Tweets from 2009-01-01 to 2011-12-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MolsonCoors Tweets\n",
      "Pulling NewmontCorp Tweets from 2009-01-01 to 2012-01-11\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling NewmontCorp Tweets\n",
      "File Empty. Pulling MylanNews Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MylanNews Tweets\n",
      "Pulling MandT_Bank Tweets from 2009-01-01 to 2010-06-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MandT_Bank Tweets\n",
      "Pulling johnsoncontrols Tweets from 2009-01-01 to 2013-04-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling johnsoncontrols Tweets\n",
      "Pulling amphenol Tweets from 2009-01-01 to 2015-10-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling amphenol Tweets\n",
      "Pulling TRowePrice Tweets from 2009-01-01 to 2012-02-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling TRowePrice Tweets\n",
      "Pulling EversourceCorp Tweets from 2009-01-01 to 2009-10-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling EversourceCorp Tweets\n",
      "Pulling TysonFoods Tweets from 2009-01-01 to 2009-01-02\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling TysonFoods Tweets\n",
      "Pulling IntlPaperCo Tweets from 2009-01-01 to 2013-07-11\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling IntlPaperCo Tweets\n",
      "Pulling WTWcorporate Tweets from 2009-01-01 to 2016-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WTWcorporate Tweets\n",
      "Pulling ADI_News Tweets from 2009-01-01 to 2009-05-04\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ADI_News Tweets\n",
      "Pulling Paychex Tweets from 2009-01-01 to 2010-01-11\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Paychex Tweets\n",
      "Pulling TheHartford Tweets from 2009-01-01 to 2009-06-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling TheHartford Tweets\n",
      "File Empty. Pulling bathandbodyworks Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 400\n",
      "ERROR CODE 400: This account doesn't appear to exist. Check Twitter Handle and try again in the future.\n",
      "Total number of results:  0\n",
      "Finished Pulling bathandbodyworks Tweets\n",
      "Pulling StanleyBlkDeckr Tweets from 2009-01-01 to 2010-03-12\n",
      "File Already Exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling StanleyBlkDeckr Tweets\n",
      "Pulling KeurigPepper Tweets from 2009-01-01 to 2019-05-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling KeurigPepper Tweets\n",
      "Pulling Cerner Tweets from 2009-01-01 to 2009-06-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Cerner Tweets\n",
      "Pulling smuckers Tweets from 2009-01-01 to 2013-08-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling smuckers Tweets\n",
      "Pulling moodyscorp Tweets from 2009-01-01 to 2016-04-25\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling moodyscorp Tweets\n",
      "Pulling ameriprise Tweets from 2009-01-01 to 2011-05-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ameriprise Tweets\n",
      "Pulling Clorox Tweets from 2009-01-01 to 2010-02-24\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  133\n",
      "Total Tweets Added:  133\n",
      "Total number of results:  133\n",
      "Finished Pulling Clorox Tweets\n",
      "Pulling DTE_Energy Tweets from 2009-01-01 to 2010-07-06\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  278\n",
      "Total Tweets Added:  278\n",
      "Total number of results:  278\n",
      "Finished Pulling DTE_Energy Tweets\n",
      "Pulling IRProducts Tweets from 2009-01-01 to 2009-11-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling IRProducts Tweets\n",
      "Pulling BDandCo Tweets from 2009-01-01 to 2009-12-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling BDandCo Tweets\n",
      "Pulling ConchoOilfield Tweets from 2009-01-01 to 2013-05-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ConchoOilfield Tweets\n",
      "Pulling Chevron Tweets from 2009-01-01 to 2009-02-16\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Chevron Tweets\n",
      "File Empty. Pulling NucorCorp Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling NucorCorp Tweets\n",
      "Pulling Brkfldproprtl Tweets from 2009-01-01 to 2012-06-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Brkfldproprtl Tweets\n",
      "Pulling RealtyIncome Tweets from 2009-01-01 to 2012-02-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling RealtyIncome Tweets\n",
      "Pulling HessCorporation Tweets from 2009-01-01 to 2011-08-17\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling HessCorporation Tweets\n",
      "Pulling WilliamsUpdates Tweets from 2009-01-01 to 2009-02-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WilliamsUpdates Tweets\n",
      "Pulling united Tweets from 2009-01-01 to 2011-05-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling united Tweets\n",
      "File Empty. Pulling meadjohnson Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling meadjohnson Tweets\n",
      "Pulling ROKAutomation Tweets from 2009-01-01 to 2010-02-22\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ROKAutomation Tweets\n",
      "Pulling ParkerHannifin Tweets from 2009-01-01 to 2010-02-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ParkerHannifin Tweets\n",
      "File Empty. Pulling Vulcan_Concrete Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Vulcan_Concrete Tweets\n",
      "Pulling DentsplySirona Tweets from 2009-01-01 to 2012-04-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DentsplySirona Tweets\n",
      "Pulling NorthernTrust Tweets from 2009-01-01 to 2011-06-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling NorthernTrust Tweets\n",
      "Pulling CBSTweet Tweets from 2009-01-01 to 2009-03-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CBSTweet Tweets\n",
      "Pulling CenturyLink Tweets from 2009-01-01 to 2010-04-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CenturyLink Tweets\n",
      "Pulling ultabeauty Tweets from 2009-01-01 to 2009-04-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling ultabeauty Tweets\n",
      "Pulling Agilent Tweets from 2009-01-01 to 2009-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Agilent Tweets\n",
      "Pulling digitalrealty Tweets from 2009-01-01 to 2009-05-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling digitalrealty Tweets\n",
      "Pulling Equifax Tweets from 2009-01-01 to 2011-04-18\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Equifax Tweets\n",
      "Pulling HenrySchein Tweets from 2009-01-01 to 2010-01-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling HenrySchein Tweets\n",
      "Pulling PerrigoCompany Tweets from 2009-01-01 to 2015-09-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling PerrigoCompany Tweets\n",
      "Pulling CenturyLink Tweets from 2009-01-01 to 2010-04-15\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling CenturyLink Tweets\n",
      "Pulling FifthThird Tweets from 2009-01-01 to 2011-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling FifthThird Tweets\n",
      "Pulling Healthcare_ABC Tweets from 2009-01-01 to 2011-10-11\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Healthcare_ABC Tweets\n",
      "Pulling genuinepartsco Tweets from 2009-01-01 to 2019-05-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling genuinepartsco Tweets\n",
      "Pulling firstenergycorp Tweets from 2009-01-01 to 2011-10-26\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling firstenergycorp Tweets\n",
      "Pulling RedHat Tweets from 2009-01-01 to 2009-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling RedHat Tweets\n",
      "Pulling Entergy Tweets from 2009-01-01 to 2009-11-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Entergy Tweets\n",
      "Pulling WhirlpoolCorp Tweets from 2009-01-01 to 2009-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WhirlpoolCorp Tweets\n",
      "Pulling Hersheys Tweets from 2009-01-01 to 2011-10-07\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Hersheys Tweets\n",
      "Pulling awwa Tweets from 2009-01-01 to 2009-12-08\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling awwa Tweets\n",
      "Pulling EssexApartments Tweets from 2009-01-01 to 2009-03-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling EssexApartments Tweets\n",
      "Pulling NOVGlobal Tweets from 2009-01-01 to 2014-08-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling NOVGlobal Tweets\n",
      "Pulling FM_FCX Tweets from 2009-01-01 to 2019-12-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling FM_FCX Tweets\n",
      "Pulling WesternDigital Tweets from 2009-01-01 to 2017-02-10\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling WesternDigital Tweets\n",
      "Pulling citrix Tweets from 2009-01-01 to 2009-06-09\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling citrix Tweets\n",
      "Pulling LABCORP Tweets from 2009-01-01 to 2020-03-20\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling LABCORP Tweets\n",
      "Pulling LamResearch Tweets from 2009-01-01 to 2014-04-23\n",
      "File Already Exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling LamResearch Tweets\n",
      "Pulling EQTCorp Tweets from 2009-01-01 to 2017-11-13\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling EQTCorp Tweets\n",
      "File Empty. Pulling AllianceData Tweets from 2009-01-01 to 2022-12-31\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling AllianceData Tweets\n",
      "Pulling FastenalCompany Tweets from 2009-01-01 to 2010-03-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling FastenalCompany Tweets\n",
      "Pulling skyworksinc Tweets from 2009-01-01 to 2009-06-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling skyworksinc Tweets\n",
      "Pulling autodesk Tweets from 2009-01-01 to 2009-05-25\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling autodesk Tweets\n",
      "Pulling MicronTech Tweets from 2009-01-01 to 2009-01-23\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling MicronTech Tweets\n",
      "Pulling Alcoa Tweets from 2009-01-01 to 2009-01-05\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Alcoa Tweets\n",
      "Pulling RoyalCaribbean Tweets from 2009-01-01 to 2010-08-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  500\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  500\n",
      "Finished Pulling RoyalCaribbean Tweets\n",
      "Pulling Expedia Tweets from 2009-01-01 to 2009-01-01\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Expedia Tweets\n",
      "Pulling grainger Tweets from 2009-01-01 to 2012-01-27\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling grainger Tweets\n",
      "Pulling FTI_US Tweets from 2009-01-01 to 2011-08-04\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling FTI_US Tweets\n",
      "Pulling DaVita Tweets from 2009-01-01 to 2009-10-28\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling DaVita Tweets\n",
      "Pulling Marriott Tweets from 2009-01-01 to 2010-10-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Marriott Tweets\n",
      "Pulling mhkgreenworks Tweets from 2009-01-01 to 2014-07-21\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling mhkgreenworks Tweets\n",
      "Pulling 21CF Tweets from 2009-01-01 to 2013-06-29\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling 21CF Tweets\n",
      "Pulling Marriott Tweets from 2009-01-01 to 2010-10-14\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Marriott Tweets\n",
      "Pulling Tractor Supply Tweets from 2009-01-01 to 2015-09-19\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling Tractor Supply Tweets\n",
      "Pulling RegionsNews Tweets from 2009-01-01 to 2013-12-12\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "Total number of results:  0\n",
      "Finished Pulling RegionsNews Tweets\n",
      "Pulling ChipotleTweets Tweets from 2009-01-01 to 2020-07-30\n",
      "File Already Exists!\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  1000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  1500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  2000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  2500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  3000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  3500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  4000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  4500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  5000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  5500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  6000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  6500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  7000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  7500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  8000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  8500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  9000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  9500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  10000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  10500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  11000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  11500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  12000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  12500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  13000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  13500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  14000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  14500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  15000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  15500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  16000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  16500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  17000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  17500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  18000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  18500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  19000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  19500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  20000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  20500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  21000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  21500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  22000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  22500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  23000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  23500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  24000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  24500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  25000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  25500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  26000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  26500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  27000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  27500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  28000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  28500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  29000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  29500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  30000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  30500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  31000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  31500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  32000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  32500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  33000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  33500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  34000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  34500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  35000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  35500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  36000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  36500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  37000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  37500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  38000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  38500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  39000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  39500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  40000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  40500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  41000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  41500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  42000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  42500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  43000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  43500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  44000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  44500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  45000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  45500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  46000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  46500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  47000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  47500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  48000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  48500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  49000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  49500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  50000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  50500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  51000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  51500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  52000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  52500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  53000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  53500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  54000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  54500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  55000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  55500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  56000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  56500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  57000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  57500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  58000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  58500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  59000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  59500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  60000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  60500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  61000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  61500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  62000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  62500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  63000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  63500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  64000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  64500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  65000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  65500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  66000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  66500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  67000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  67500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  68000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  68500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  69000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  69500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  70000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  70500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  71000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  71500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  72000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  72500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  73000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  73500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  74000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  74500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  75000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  75500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  76000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  76500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  77000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  77500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  78000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  78500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  79000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  79500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  80000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  80500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  81000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  81500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  82000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  82500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  83000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  83500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  84000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  84500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  85000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  85500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  86000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  86500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  87000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  87500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  88000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  88500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  89000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  89500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  90000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  90500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  91000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  91500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  92000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  92500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  93000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  93500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  94000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  94500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  95000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  95500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  96000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  96500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  97000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  97500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  98000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  98500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  99000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  99500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  100000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  100500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  101000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  101500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  102000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  102500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  103000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  103500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  104000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  104500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  105000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  105500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  106000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  106500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  107000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  107500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  108000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  108500\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  109000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  109500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  110000\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  499\n",
      "Total Tweets Added:  110499\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  110999\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  111499\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  111999\n",
      "Endpoint Response Code: 200\n",
      "# of Tweets added from this response:  500\n",
      "Total Tweets Added:  112499\n",
      "Endpoint Response Code: 429\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "(429, '{\"account_id\":1598398401024065554,\"product_name\":\"academic\",\"title\":\"UsageCapExceeded\",\"period\":\"Monthly\",\"scope\":\"Product\",\"detail\":\"Usage cap exceeded: Monthly product cap\",\"type\":\"https://api.twitter.com/2/problems/usage-capped\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c579ee83ec2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmass_pull_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorp_twitter_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccount_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Corporate\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-2ae3b01d5c9d>\u001b[0m in \u001b[0;36mmass_pull_data\u001b[1;34m(account_list, account_type, update)\u001b[0m\n\u001b[0;32m    224\u001b[0m                     \u001b[0mlast_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%dT%H:%M:%S.%f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"Z\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pulling '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0maccount\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Tweets from 2009-01-01 to '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                     \u001b[0mpull_account_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlast_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished Pulling '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0maccount\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Tweets'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                     \u001b[1;31m#create_summary_data(twitter_handle=account, account_type=account_type, company_data=company_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-2ae3b01d5c9d>\u001b[0m in \u001b[0;36mpull_account_tweets\u001b[1;34m(twitter_handle, start_date, end_date)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mjson_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnect_to_endpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjson_response\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-2ae3b01d5c9d>\u001b[0m in \u001b[0;36mconnect_to_endpoint\u001b[1;34m(url, headers, params, next_token)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: (429, '{\"account_id\":1598398401024065554,\"product_name\":\"academic\",\"title\":\"UsageCapExceeded\",\"period\":\"Monthly\",\"scope\":\"Product\",\"detail\":\"Usage cap exceeded: Monthly product cap\",\"type\":\"https://api.twitter.com/2/problems/usage-capped\"}')"
     ]
    }
   ],
   "source": [
    "mass_pull_data(corp_twitter_list, account_type = \"Corporate\", update_backwards=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newest Date: 2022-11-28 23:00:00+00:00\n",
      "Oldest Date: 2022-01-01 00:48:52+00:00\n"
     ]
    }
   ],
   "source": [
    "# Want to create the update_forward function, which should read in data file, coerce date column to being a date,\n",
    "# sort by date with newest date at top, take that newest date as input to pull_account_tweets with forward_year\n",
    "# providing the last date (ex: foward_year=2022 means that last date should be 12-31-22)\n",
    "account_type = 'Corporate'\n",
    "account = 'ATT'\n",
    "forward_year = 2022\n",
    "\n",
    "path = Path(account_type + \" Account Data/\"+str(account)+\".csv\")\n",
    "data = pd.read_csv(path)\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data = data.sort_values('created_at', ascending=False)\n",
    "data_new_year = data[data['created_at'].dt.year == forward_year]\n",
    "newest_date = data_new_year['created_at'].iloc[0]\n",
    "oldest_date = data_new_year['created_at'].iloc[-1]\n",
    "print(f'Newest Date: {newest_date}')\n",
    "print(f'Oldest Date: {oldest_date}')\n",
    "# if path.is_file():\n",
    "#     # If the path to that file already exists, check if it's empty\n",
    "#     data = pd.read_csv(account_type + \" Account Data/\"+str(account)+\".csv\")\n",
    "#     if data.empty:\n",
    "#         # Pull data for the empty file\n",
    "#         print('File Empty. Pulling ' + account + ' Tweets from 2009-01-01 to 2022-12-31')\n",
    "#         pull_account_tweets(account, account_type)\n",
    "#         print('Finished Pulling ' + account + ' Tweets')\n",
    "#     else:\n",
    "#         data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "#         data = data.sort_values('created_at', ascending=False)\n",
    "#         start_date = data['created_at'][0]\n",
    "#         start_date = start_date.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]+\"Z\"\n",
    "#         end_date = str(forward_year) + \"-12-31T00:00:00.000Z\"\n",
    "#         print('Pulling ' + account + ' Tweets from ' + str(start_date[:10]) + ' to ' + str(end_date[:10]))\n",
    "#         #pull_account_tweets(account, account_type, start_date=start_date, end_date=end_date)\n",
    "#         print('Finished Pulling ' + account + ' Tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'Microsoft',\n",
       " 'exxonmobil',\n",
       " 'JNJNews',\n",
       " 'generalelectric',\n",
       " 'amazon',\n",
       " 'facebook',\n",
       " 'ATT',\n",
       " 'jpmorgan',\n",
       " 'WellsFargo',\n",
       " 'ProcterGamble',\n",
       " 'google',\n",
       " 'google',\n",
       " 'pfizer',\n",
       " 'verizon',\n",
       " 'Chevron',\n",
       " 'CocaColaCo',\n",
       " 'HomeDepot',\n",
       " 'Merck',\n",
       " 'InsidePMI',\n",
       " 'Visa',\n",
       " 'comcast',\n",
       " 'intel',\n",
       " 'PepsiCo',\n",
       " 'Disney',\n",
       " 'Cisco',\n",
       " 'BankofAmerica',\n",
       " 'IBM',\n",
       " 'UnitedHealthGrp',\n",
       " 'Citi',\n",
       " 'AltriaNews',\n",
       " 'Oracle',\n",
       " 'bmsnews',\n",
       " 'Medtronic',\n",
       " 'Amgen',\n",
       " 'GileadSciences',\n",
       " 'Walmart',\n",
       " 'McDonaldsCorp',\n",
       " 'CVSHealth',\n",
       " '3M',\n",
       " 'abbvie',\n",
       " 'abbvie',\n",
       " 'MasterCard',\n",
       " 'Honeywell',\n",
       " 'bmsnews',\n",
       " 'Boeing',\n",
       " 'Qualcomm',\n",
       " 'Starbucks',\n",
       " 'UTC',\n",
       " 'UnionPacific',\n",
       " 'Accenture',\n",
       " 'Nike',\n",
       " 'UPS',\n",
       " 'LillyPad',\n",
       " 'Lowes',\n",
       " 'MDLZ',\n",
       " 'usbank',\n",
       " 'WBA_Global',\n",
       " 'priceline',\n",
       " 'CP_News',\n",
       " 'AIGinsurance',\n",
       " 'LockheedMartin',\n",
       " 'TXInstruments',\n",
       " 'SimonPropertyGp',\n",
       " 'thermofisher',\n",
       " 'Broadcom',\n",
       " 'GoldmanSachs',\n",
       " 'DanaherCorp',\n",
       " 'DowNewsroom',\n",
       " 'wbd',\n",
       " 'DuPont_News',\n",
       " 'Chubb',\n",
       " 'WeAreOxy',\n",
       " 'conocophillips',\n",
       " 'AbbottNews',\n",
       " 'nexteraenergy',\n",
       " 'DukeEnergy',\n",
       " 'biogen',\n",
       " 'DellEMC',\n",
       " 'AmericanExpress',\n",
       " 'salesforce',\n",
       " 'tjmaxx',\n",
       " 'Ford',\n",
       " 'KraftHeinzCo',\n",
       " 'Adobe',\n",
       " 'ExpressScripts',\n",
       " 'Bayer',\n",
       " 'MetLife',\n",
       " 'KCCorp',\n",
       " 'SouthernCompany',\n",
       " 'AmericanTowerUS',\n",
       " 'blackrock',\n",
       " 'CaterpillarInc',\n",
       " 'BNYMellon',\n",
       " 'PNCBank',\n",
       " 'DominionEnergy',\n",
       " 'McKesson',\n",
       " 'Aetna',\n",
       " 'RAI_News',\n",
       " 'FedEx',\n",
       " 'netflix',\n",
       " 'GDMS',\n",
       " 'PayPal',\n",
       " 'GM',\n",
       " 'RaytheonTech',\n",
       " 'Target',\n",
       " 'ADP',\n",
       " 'MorganStanley',\n",
       " 'northropgrumman',\n",
       " 'Halliburton',\n",
       " 'GeneralMills',\n",
       " 'Phillips66Co',\n",
       " 'CapitalOne',\n",
       " 'Cognizant',\n",
       " 'PublicStorage',\n",
       " 'StrykerEndo',\n",
       " 'BDandCo',\n",
       " 'kroger',\n",
       " 'ITWInc',\n",
       " 'CharlesSchwab',\n",
       " 'AnthemInc',\n",
       " 'MMC_Global',\n",
       " 'Emerson_News',\n",
       " 'yumbrands',\n",
       " 'Travelers',\n",
       " 'HPE',\n",
       " 'Prudential',\n",
       " 'Kinder_Morgan',\n",
       " 'Cigna',\n",
       " 'Delta',\n",
       " 'AEPnews',\n",
       " '21CF',\n",
       " 'Yahoo',\n",
       " 'Exelon',\n",
       " 'Ecolab',\n",
       " 'CMEGroup',\n",
       " 'CrownCastle',\n",
       " 'bostonsci',\n",
       " 'ICE_Markets',\n",
       " 'AlexionPharma',\n",
       " 'PGE4Me',\n",
       " 'regeneron',\n",
       " 'Aon_plc',\n",
       " 'PPG',\n",
       " 'TruistNews',\n",
       " 'Aflac',\n",
       " 'SPGlobal',\n",
       " 'johnsoncontrols',\n",
       " 'eatoncorp',\n",
       " 'airproducts',\n",
       " 'SouthwestAir',\n",
       " 'Humana',\n",
       " 'WeAreOxy',\n",
       " 'LyondellBasell',\n",
       " 'semiwestapplied',\n",
       " 'Intuit',\n",
       " 'cbrands',\n",
       " 'PXDtweets',\n",
       " 'DollarGeneral',\n",
       " 'PPLCorp',\n",
       " 'eBay',\n",
       " 'Synchrony',\n",
       " 'Prologis',\n",
       " 'cardinalhealth',\n",
       " 'ADMupdates',\n",
       " 'CSX',\n",
       " 'JohnDeere',\n",
       " 'WasteManagement',\n",
       " 'SempraEnergy',\n",
       " 'Sysco',\n",
       " 'Equinix',\n",
       " 'Allstate',\n",
       " 'Welltower',\n",
       " 'nscorp',\n",
       " 'oreillyauto',\n",
       " 'ValeroEnergy_',\n",
       " 'HCAhealthcare',\n",
       " 'baxter_intl',\n",
       " 'IntuitiveSurg',\n",
       " 'nvidia',\n",
       " 'StateStreet',\n",
       " 'edisonintl',\n",
       " 'Fiserv',\n",
       " 'HP',\n",
       " 'EA',\n",
       " 'Discover',\n",
       " 'EquityRes',\n",
       " 'Corning',\n",
       " 'AvalonBay',\n",
       " 'TEConnectivity',\n",
       " 'VentasREIT',\n",
       " 'SherwinWilliams',\n",
       " 'autozone',\n",
       " 'VertexPharma',\n",
       " 'Weyerhaeuser',\n",
       " 'SpectraEnergy',\n",
       " 'PSEGNews',\n",
       " 'ConEdison',\n",
       " 'newell_brands',\n",
       " 'CBSTweet',\n",
       " 'SJM_Media',\n",
       " 'Zoetis',\n",
       " 'EdwardsLifesci',\n",
       " 'Ross_Stores',\n",
       " 'MonsterEnergy',\n",
       " 'TruistNews',\n",
       " 'xcelenergy',\n",
       " 'CarnivalPLC',\n",
       " 'DollarTree',\n",
       " 'VFCorp',\n",
       " 'zimmerbiomet',\n",
       " 'APA_Corp',\n",
       " 'illumina',\n",
       " 'bakerhughesco',\n",
       " 'FISGlobal',\n",
       " 'EsteeLauder',\n",
       " 'ConagraBrands',\n",
       " 'Omnicom',\n",
       " 'AmericanAir',\n",
       " 'Nielsen',\n",
       " 'SustainableBXP',\n",
       " 'PACCARFinancial',\n",
       " 'WECEnergyGroup',\n",
       " 'KelloggCompany',\n",
       " 'MarathonPetroCo',\n",
       " 'ATVI_AB',\n",
       " 'Cummins',\n",
       " 'Progressive',\n",
       " 'DelphiAuto',\n",
       " 'DevonEnergy',\n",
       " 'MolsonCoors',\n",
       " 'NewmontCorp',\n",
       " 'MylanNews',\n",
       " 'MandT_Bank',\n",
       " 'johnsoncontrols',\n",
       " 'amphenol',\n",
       " 'TRowePrice',\n",
       " 'EversourceCorp',\n",
       " 'TysonFoods',\n",
       " 'IntlPaperCo',\n",
       " 'WTWcorporate',\n",
       " 'ADI_News',\n",
       " 'Paychex',\n",
       " 'TheHartford',\n",
       " 'bathandbodyworks',\n",
       " 'StanleyBlkDeckr',\n",
       " 'KeurigPepper',\n",
       " 'Cerner',\n",
       " 'smuckers',\n",
       " 'moodyscorp',\n",
       " 'ameriprise',\n",
       " 'Clorox',\n",
       " 'DTE_Energy',\n",
       " 'IRProducts',\n",
       " 'BDandCo',\n",
       " 'ConchoOilfield',\n",
       " 'Chevron',\n",
       " 'NucorCorp',\n",
       " 'Brkfldproprtl',\n",
       " 'RealtyIncome',\n",
       " 'HessCorporation',\n",
       " 'WilliamsUpdates',\n",
       " 'united',\n",
       " 'meadjohnson',\n",
       " 'ROKAutomation',\n",
       " 'ParkerHannifin',\n",
       " 'Vulcan_Concrete',\n",
       " 'DentsplySirona',\n",
       " 'NorthernTrust',\n",
       " 'CBSTweet',\n",
       " 'CenturyLink',\n",
       " 'ultabeauty',\n",
       " 'Agilent',\n",
       " 'digitalrealty',\n",
       " 'Equifax',\n",
       " 'HenrySchein',\n",
       " 'PerrigoCompany',\n",
       " 'CenturyLink',\n",
       " 'FifthThird',\n",
       " 'Healthcare_ABC',\n",
       " 'genuinepartsco',\n",
       " 'firstenergycorp',\n",
       " 'RedHat',\n",
       " 'Entergy',\n",
       " 'WhirlpoolCorp',\n",
       " 'Hersheys',\n",
       " 'awwa',\n",
       " 'EssexApartments',\n",
       " 'NOVGlobal',\n",
       " 'FM_FCX',\n",
       " 'WesternDigital',\n",
       " 'citrix',\n",
       " 'LABCORP',\n",
       " 'LamResearch',\n",
       " 'EQTCorp',\n",
       " 'AllianceData',\n",
       " 'FastenalCompany',\n",
       " 'skyworksinc',\n",
       " 'autodesk',\n",
       " 'MicronTech',\n",
       " 'Alcoa',\n",
       " 'RoyalCaribbean',\n",
       " 'Expedia',\n",
       " 'grainger',\n",
       " 'FTI_US',\n",
       " 'DaVita',\n",
       " 'Marriott',\n",
       " 'mhkgreenworks',\n",
       " '21CF',\n",
       " 'Marriott',\n",
       " 'Tractor Supply',\n",
       " 'RegionsNews',\n",
       " 'ChipotleTweets',\n",
       " 'UHS_Inc',\n",
       " 'AmerenCorp',\n",
       " 'Verisk',\n",
       " 'MartinMarietta',\n",
       " 'kimcorealty',\n",
       " 'InvescoUS',\n",
       " 'CitizensBank',\n",
       " 'MarathonOil',\n",
       " 'ConsumersEnergy',\n",
       " 'XilinxInc',\n",
       " 'CoterraEnergy',\n",
       " 'CollinsAero',\n",
       " 'RepublicService',\n",
       " 'GlobalPayInc',\n",
       " 'principal',\n",
       " 'Centene',\n",
       " 'McCormickCorp',\n",
       " 'AdvanceAuto',\n",
       " 'AMETEKInc',\n",
       " 'L3HarrisTech',\n",
       " 'LinearTech',\n",
       " 'Cimarex',\n",
       " 'KLAcorp',\n",
       " 'watercorpwa',\n",
       " 'AcuityBrands',\n",
       " 'WholeFoods',\n",
       " 'MicrochipTech',\n",
       " 'QuestDX',\n",
       " 'CampbellSoupCo',\n",
       " 'extraspace',\n",
       " 'DoverCorp',\n",
       " 'Pentair',\n",
       " 'FederalRealty',\n",
       " 'Mattel',\n",
       " 'MotoSolutions',\n",
       " 'Coach',\n",
       " 'Lcareers',\n",
       " 'lincolnfingroup',\n",
       " 'Textron',\n",
       " 'CHRobinsonInc',\n",
       " 'BallCorpHQ',\n",
       " 'EastmanChemCo',\n",
       " 'symantec',\n",
       " 'Hanes',\n",
       " 'DRHorton',\n",
       " 'Macys',\n",
       " 'keybank',\n",
       " 'IFF',\n",
       " 'scanaenergy',\n",
       " 'WestRock',\n",
       " 'TCEnergy',\n",
       " 'SLGreen',\n",
       " 'LKQCorp',\n",
       " 'CarMax',\n",
       " 'L3HarrisTech',\n",
       " 'CenterPoint',\n",
       " 'brownforman',\n",
       " 'MacerichCo',\n",
       " 'WesternUnion',\n",
       " 'Akamai',\n",
       " 'XLCatlin',\n",
       " 'CanadianPacific',\n",
       " 'Hasbro',\n",
       " 'ONEOK',\n",
       " 'CAinc',\n",
       " 'InterpublicIPG',\n",
       " 'MosaicCompany',\n",
       " 'Xerox',\n",
       " 'HormelFoods',\n",
       " 'Andeavor',\n",
       " 'Snapon_Tools',\n",
       " 'Sealed_Air',\n",
       " 'MichaelKors',\n",
       " 'EXPD_Official',\n",
       " 'UDRMarketing',\n",
       " 'GlobalPayInc',\n",
       " 'IronMountain',\n",
       " 'CBRE',\n",
       " 'Hologic',\n",
       " 'Lennar',\n",
       " 'Stericycle_Inc',\n",
       " 'GallagherGlobal',\n",
       " 'unumnews',\n",
       " 'BestBuy',\n",
       " 'AlaskaAir',\n",
       " 'CintasCorp',\n",
       " 'harleydavidson',\n",
       " 'XylemInc',\n",
       " 'JuniperNetworks',\n",
       " 'F5',\n",
       " 'WynnLasVegas',\n",
       " 'VERISIGN',\n",
       " 'NFXCo',\n",
       " 'VarianMedSys',\n",
       " 'Huntington_Bank',\n",
       " 'NiSourceInc',\n",
       " 'PVHCorp',\n",
       " 'SouthernCompany',\n",
       " 'ComericaBank',\n",
       " 'TripAdvisor',\n",
       " 'darden',\n",
       " 'Range_Resources',\n",
       " 'AlticeUSA',\n",
       " 'Wyndham',\n",
       " 'footlocker',\n",
       " 'BorgWarner',\n",
       " 'TheAESCorp',\n",
       " 'NASDAQ',\n",
       " 'etrade',\n",
       " 'FluorCorp',\n",
       " 'goodyear',\n",
       " 'JBHuntDrivers',\n",
       " 'HelmerichPayne',\n",
       " 'QorvoInc',\n",
       " 'NetApp',\n",
       " 'BedBathBeyond',\n",
       " 'Seagate',\n",
       " 'SignetJewelers',\n",
       " 'Kohls',\n",
       " 'UnderArmour',\n",
       " 'MNK',\n",
       " 'TiffanyAndCo',\n",
       " 'CFIndustries',\n",
       " 'leggettandplatt',\n",
       " 'AveryDennison',\n",
       " 'GlobeLife',\n",
       " 'Flowserve',\n",
       " 'United_Rentals',\n",
       " 'FMCCorp',\n",
       " 'AllegionPlc',\n",
       " 'UnderArmour',\n",
       " 'TECOEnergy',\n",
       " 'JacobsConnects',\n",
       " 'FMC_Tech',\n",
       " 'AimcoApts',\n",
       " 'Discovery',\n",
       " 'PulteHomes',\n",
       " 'ScrippsNet',\n",
       " 'FrontierCorp',\n",
       " 'PerkinElmer',\n",
       " 'Jefferies',\n",
       " 'ZionsBank',\n",
       " 'SWN_R2',\n",
       " 'Harman',\n",
       " 'Staples',\n",
       " 'RalphLauren',\n",
       " 'Assurant',\n",
       " 'roberthalf',\n",
       " 'nrgenergy',\n",
       " 'MurphyOilCorp',\n",
       " 'Garmin',\n",
       " 'HRBlock',\n",
       " 'Nordstrom',\n",
       " 'TEGNA',\n",
       " 'PeoplesUnited',\n",
       " 'DunBradstreet',\n",
       " 'Navient',\n",
       " 'newscorp',\n",
       " 'GapInc',\n",
       " 'flir',\n",
       " 'Discovery',\n",
       " 'TransoceanValue',\n",
       " 'FirstSolar',\n",
       " 'Teradata',\n",
       " 'AutoNation',\n",
       " 'EndoIntlplc',\n",
       " 'Quanta_Services',\n",
       " 'RyderSystemInc',\n",
       " 'PitneyBowes',\n",
       " 'FTI_US',\n",
       " 'CSRA_inc',\n",
       " 'OI_Glass',\n",
       " 'Chesapeake',\n",
       " 'UrbanOutfitters',\n",
       " 'newscorp',\n",
       " 'mettlertoledo',\n",
       " 'FBHS_News',\n",
       " 'CDKGlobal',\n",
       " 'AlbemarleCorp',\n",
       " 'alliantenergy',\n",
       " 'Ingredion',\n",
       " 'DukeRealty',\n",
       " 'ResMed',\n",
       " 'Gartner_inc',\n",
       " 'Danone',\n",
       " 'IDEXX',\n",
       " 'synopsys',\n",
       " 'evergypower',\n",
       " 'Valspar',\n",
       " 'ANSYS',\n",
       " 'atmosenergy',\n",
       " 'regencycenters',\n",
       " 'WeAreHII',\n",
       " 'EverestIns',\n",
       " 'Cadence',\n",
       " 'Broadridge',\n",
       " 'UGICorporation',\n",
       " 'MAACommunities',\n",
       " 'AshlandInc',\n",
       " 'CSCGlobal',\n",
       " 'teleflex',\n",
       " 'WabtecCorp',\n",
       " 'SignatureBankNY',\n",
       " 'SEIInvestments',\n",
       " 'CamdenLiving',\n",
       " 'RaymondJames',\n",
       " 'MSCI_Inc',\n",
       " 'RPMintl',\n",
       " 'JackHenryAssoc',\n",
       " 'NNNreit',\n",
       " 'IDEXCorp',\n",
       " 'FactSet',\n",
       " 'TrimbleCorpNews',\n",
       " 'pediatrix',\n",
       " 'packagingcorp',\n",
       " 'RGA_RE',\n",
       " 'AOSmithHotWater',\n",
       " 'dominos',\n",
       " 'OGEEnergyCorp',\n",
       " 'americancampus',\n",
       " 'ArrowGlobal',\n",
       " 'STERIS',\n",
       " 'UltimateHCM',\n",
       " 'MyAquaAmerica',\n",
       " 'JetBlue',\n",
       " 'Invisalign',\n",
       " 'Kilroyrealty',\n",
       " 'ManpowerGroup',\n",
       " 'LibPropTrust',\n",
       " 'HubbellCorp',\n",
       " 'Avnet',\n",
       " 'LennoxAir',\n",
       " 'WestPharma',\n",
       " 'WRBerkleyCorp',\n",
       " 'JLL',\n",
       " 'Reliance_RS',\n",
       " 'SVB_Financial',\n",
       " 'EastWestBancorp',\n",
       " 'Carters',\n",
       " 'Keysight',\n",
       " 'MarketAxess',\n",
       " 'OrbitalATK',\n",
       " 'VCAPetHealth',\n",
       " 'LamarOOH',\n",
       " 'tylertech',\n",
       " 'IngramMicroInc',\n",
       " 'haincelestial',\n",
       " 'CBOE',\n",
       " 'RaytheonTech',\n",
       " 'PolarisCareers',\n",
       " 'copartdirect',\n",
       " 'AECOM',\n",
       " 'panerabread',\n",
       " 'Fortinet',\n",
       " 'PostCereals',\n",
       " 'ManhAssocNews',\n",
       " 'aptar',\n",
       " 'Sonoco_Products',\n",
       " 'TheToroCompany',\n",
       " 'BemisCompanyInc',\n",
       " 'natfuelgas',\n",
       " 'DouglasEmmett',\n",
       " 'HighwoodsProp',\n",
       " 'RenReinsurance',\n",
       " 'energen',\n",
       " 'EPRInsight',\n",
       " 'GentexCorp',\n",
       " 'BankPacWest',\n",
       " 'LifeStorage',\n",
       " 'caseysgenstore',\n",
       " 'Nordson_Corp',\n",
       " 'oldrepublicpro',\n",
       " 'MDUResources',\n",
       " '@tollbrothers',\n",
       " 'WellcarePlans',\n",
       " 'GracoInc',\n",
       " 'kimcorealty',\n",
       " 'FEI_Company',\n",
       " 'DominionEnergy',\n",
       " 'AmSurgCorp',\n",
       " 'PTC',\n",
       " 'Brunswick_Corp_',\n",
       " 'WilliamsSonoma',\n",
       " 'ARRIS',\n",
       " 'CenterPoint',\n",
       " 'heTaubmanCo',\n",
       " 'biotechne',\n",
       " 'bbinsny',\n",
       " 'ODFLInc',\n",
       " 'endurance',\n",
       " 'EnergyGulfport',\n",
       " 'Broadcom',\n",
       " 'EatonVance',\n",
       " 'dunkindonuts',\n",
       " 'Teradyneinc',\n",
       " 'FirstAm',\n",
       " 'CrackerBarrel',\n",
       " 'Abiomed',\n",
       " 'CoreCivic',\n",
       " 'CommerceBank',\n",
       " 'CRiverLabs',\n",
       " 'DCTIndustrial',\n",
       " 'SKECHERSUSA',\n",
       " 'synovus',\n",
       " 'LincolnElectric',\n",
       " 'Kirby_Corp',\n",
       " 'CWCorporation1',\n",
       " 'AGCOcorp',\n",
       " 'poolcorp',\n",
       " 'NCRCorporation',\n",
       " 'DICKS',\n",
       " 'pmcmicrosemi',\n",
       " 'TempurPedic',\n",
       " 'Cognex_Corp',\n",
       " 'dst_systems',\n",
       " 'firstniagara',\n",
       " 'idahopower',\n",
       " 'MAXIMUS_news',\n",
       " 'AMC_TV',\n",
       " 'FirstMerit',\n",
       " 'WEXIncNews',\n",
       " 'The_Hanover',\n",
       " 'Jabil',\n",
       " 'FICO',\n",
       " 'MSC_Industrial',\n",
       " 'FrostBank',\n",
       " 'Cinemark',\n",
       " 'HwnElectric',\n",
       " 'LiveNation',\n",
       " 'PB_USA',\n",
       " 'TangerOutlets',\n",
       " 'WebsterBank',\n",
       " 'WatscoInc',\n",
       " 'flowersfoods',\n",
       " 'rrdonnelley',\n",
       " 'CNOFinancial',\n",
       " 'TeledyneMarine',\n",
       " 'umpquabank',\n",
       " 'WGLanswers',\n",
       " 'oshkoshcorp',\n",
       " 'CypressSemi',\n",
       " 'cibc',\n",
       " 'CoreLogicInc',\n",
       " 'sproutsfm',\n",
       " 'CONSOL_Energy',\n",
       " 'FirstHorizonBnk',\n",
       " 'CoucheTardQc',\n",
       " 'ViaSatInc',\n",
       " 'PAREXEL',\n",
       " 'woodward_inc',\n",
       " 'ONEGasInc',\n",
       " 'ValarisLimited',\n",
       " 'Oceaneering',\n",
       " 'Deluxe',\n",
       " 'bhenergy',\n",
       " 'AvientCorp',\n",
       " 'rayonier',\n",
       " 'ITT_Inc',\n",
       " 'SensientInd',\n",
       " 'NJNaturalGas',\n",
       " 'patterson_uti',\n",
       " 'LeidosInc',\n",
       " 'wfscorp',\n",
       " 'ziffdavis',\n",
       " 'ipgphotonics',\n",
       " 'BankOZK',\n",
       " 'Scotts_MGro',\n",
       " 'ValmontInd',\n",
       " 'MAACommunities',\n",
       " 'BioRad',\n",
       " 'BankofHawaii',\n",
       " 'LifePointHealth',\n",
       " 'SallieMae',\n",
       " 'NaborsGlobal',\n",
       " 'Energizer',\n",
       " 'ParkerHannifin',\n",
       " 'HelenofTroyLife',\n",
       " 'CraneCompany',\n",
       " 'TupperwarePR',\n",
       " 'CabotCorp',\n",
       " 'tenethealth',\n",
       " 'SuperiorEnergy',\n",
       " 'texasroadhouse',\n",
       " 'DevonEnergy',\n",
       " 'ZebraTechnology',\n",
       " 'VistaOutdoorInc',\n",
       " 'Aspen_Insurance',\n",
       " 'Lennar',\n",
       " 'HillromCorp',\n",
       " 'AMD',\n",
       " 'NIglobal',\n",
       " 'TrinityJobs',\n",
       " 'Dreamworks',\n",
       " 'GameStop',\n",
       " 'TDSYNNEX',\n",
       " 'FederatedHermes',\n",
       " 'LandstarSystem',\n",
       " 'JackBox',\n",
       " 'CleanHarbors',\n",
       " 'Ciena',\n",
       " 'BWWings',\n",
       " 'SYNNEX',\n",
       " 'Primerica',\n",
       " 'FNBSF',\n",
       " 'PNMtalk',\n",
       " 'katespadeny',\n",
       " 'regencycenters',\n",
       " 'BeldenInc',\n",
       " 'AssociatedBank',\n",
       " 'Rackspace',\n",
       " 'TDSYNNEX',\n",
       " 'TDSCorporate',\n",
       " 'edrtrust',\n",
       " 'compassminerals',\n",
       " 'AEO',\n",
       " 'BigLots',\n",
       " 'UEProperties',\n",
       " 'MurphyUSA',\n",
       " 'copt',\n",
       " 'firstindustrial',\n",
       " 'LaSalleIM',\n",
       " 'LanceSnacks',\n",
       " 'RegalRexnord',\n",
       " 'ACI_Worldwide',\n",
       " 'jcpenney',\n",
       " 'lpcorp',\n",
       " 'WileyGlobal',\n",
       " 'Stifel',\n",
       " 'U_S_Steel',\n",
       " 'Allscripts',\n",
       " 'stock_AKRX_NASD',\n",
       " 'Wolfspeed',\n",
       " 'FultonBank',\n",
       " 'DrilQuipInc',\n",
       " 'Cabelas',\n",
       " 'NETSCOUT',\n",
       " 'RowanCompanies',\n",
       " 'Owens_Minor',\n",
       " 'MackCaliProp',\n",
       " 'DomtarEveryday',\n",
       " 'WebMD',\n",
       " 'Huntington_Bank',\n",
       " 'Timken',\n",
       " 'SAICinc',\n",
       " 'SynaCorp',\n",
       " 'lexmark',\n",
       " 'Verifone',\n",
       " 'CatalentPharma',\n",
       " 'Cheesecake',\n",
       " 'TerexCorp',\n",
       " 'onsemi',\n",
       " 'Wendys',\n",
       " 'WAFDbank',\n",
       " 'mentor_graphics',\n",
       " 'sparklightcares',\n",
       " 'UNFI',\n",
       " 'JHIAdvisors',\n",
       " 'grahamholdings',\n",
       " 'KBRincorporated',\n",
       " 'KomatsuMining',\n",
       " 'Gartner_inc',\n",
       " 'molinahealth',\n",
       " 'ValleyBank',\n",
       " 'hnicorporation',\n",
       " 'InterDigitalCom',\n",
       " 'SilganPlastics',\n",
       " 'HancockWhitney',\n",
       " 'MineralsTecINC',\n",
       " 'BuyDNOW',\n",
       " 'Kennametal',\n",
       " 'Commvault',\n",
       " 'MyBXS',\n",
       " 'siliconlabs',\n",
       " 'TriumphGroup',\n",
       " 'HermanMiller',\n",
       " 'MeredithCorp',\n",
       " 'OilStatesInd',\n",
       " 'VishayIndust',\n",
       " 'AvonInsider',\n",
       " 'DanaInc_',\n",
       " 'WorthingtonInds',\n",
       " 'FTIConsulting',\n",
       " 'TRIPointeHomes',\n",
       " 'TimeInc',\n",
       " 'Granite',\n",
       " 'officedepot',\n",
       " 'Acxiom',\n",
       " 'DieboldNixdorf',\n",
       " 'HSN',\n",
       " 'Trustmark_Bank',\n",
       " 'Sothebys',\n",
       " 'CHSI_Clinics',\n",
       " 'MSAsafety',\n",
       " 'MercuryIns',\n",
       " 'COCGenworth',\n",
       " 'Macquarie',\n",
       " 'PolyCompany',\n",
       " 'AaronsCo',\n",
       " 'KemperInsurance',\n",
       " 'CarpenterTech',\n",
       " 'ibc_bank',\n",
       " 'HalyardHealth',\n",
       " 'SamuelAdamsBeer',\n",
       " 'comScore',\n",
       " 'Plantronics',\n",
       " 'Chicos',\n",
       " 'ATImetals_jobs',\n",
       " 'nytimes',\n",
       " 'DenburyInc',\n",
       " 'andeavor',\n",
       " '3dsystems',\n",
       " 'KnowlesCorp',\n",
       " 'supervaluPR',\n",
       " 'Abercrombie',\n",
       " 'WisdomTreeETFs',\n",
       " 'dressbarn',\n",
       " 'kbhome',\n",
       " 'Fossil',\n",
       " 'One_Werner',\n",
       " 'RestoHardware',\n",
       " 'Neustar',\n",
       " 'GreifInc',\n",
       " 'GUESS',\n",
       " 'adtalemglobal',\n",
       " 'NASCAR',\n",
       " 'TalenEnergy',\n",
       " 'TootsieRoll',\n",
       " 'PiedmontNG',\n",
       " 'SWGas',\n",
       " 'blackbaud',\n",
       " 'spire_energy',\n",
       " 'NuVasiveInc',\n",
       " 'NWEinfo',\n",
       " 'TheRealHCSG',\n",
       " 'EnerSysAmericas',\n",
       " 'BG_Foods',\n",
       " 'ALLETE_Inc',\n",
       " 'ProAssurance',\n",
       " 'MY100BANK',\n",
       " 'Medidata',\n",
       " 'Littelfuse',\n",
       " 'AvistaUtilities',\n",
       " 'PDCEnergy',\n",
       " 'monolithicpower',\n",
       " 'DarlingIngredie',\n",
       " 'Wintrust',\n",
       " 'CoreSite',\n",
       " 'GEOGroup',\n",
       " 'BankWithUnited',\n",
       " 'fivebelow',\n",
       " 'mbfinancialbank',\n",
       " 'CACIIntl',\n",
       " 'GlueTalk',\n",
       " 'AcadiaRealty',\n",
       " 'UMBBank',\n",
       " 'CirrusLogic',\n",
       " 'Masimo',\n",
       " 'CoherentInc',\n",
       " 'IBKR',\n",
       " 'southjerseygas',\n",
       " 'AmnealPharma',\n",
       " 'mksinstruments',\n",
       " 'TXCapitalBank',\n",
       " 'integra_life',\n",
       " 'First_Financial',\n",
       " 'CousinsREIT',\n",
       " 'NektarNews',\n",
       " 'SanminaCorp',\n",
       " 'EastGroupProp',\n",
       " 'kiterealtygroup',\n",
       " 'US_SILICA',\n",
       " 'EFIPrint',\n",
       " 'CoreMarkHQ',\n",
       " 'Selective',\n",
       " 'LexingtonRealty',\n",
       " 'Ligand_LGND',\n",
       " 'ABMFacilityServ',\n",
       " 'PSBusinessParks',\n",
       " 'NeogenCorp',\n",
       " 'WolverineWW',\n",
       " 'MonroAutoTire',\n",
       " 'HawaiianAir',\n",
       " 'SNBSays',\n",
       " 'Allegiant',\n",
       " 'BalchemCorp',\n",
       " 'HillenbrandInc',\n",
       " 'thedrewmarine',\n",
       " 'AMNHealthcare',\n",
       " 'SteveMadden',\n",
       " 'ElPasoElectric',\n",
       " 'Cardtronics',\n",
       " 'JBTCorporation',\n",
       " 'Applied_Ind',\n",
       " 'LTCreit',\n",
       " 'MatthewsIntl',\n",
       " 'MoogSDG',\n",
       " 'PapaJohns',\n",
       " 'asgninc',\n",
       " 'CBTCconnect',\n",
       " 'TetraTechINCA',\n",
       " 'MicroStrategy',\n",
       " 'lithiamotors',\n",
       " 'Gannett',\n",
       " 'UniFirst_Corp',\n",
       " 'UFPInc',\n",
       " 'BarnesNext',\n",
       " 'Old_National',\n",
       " 'PNFP',\n",
       " 'exl_service',\n",
       " 'ItronInc',\n",
       " 'Anixter',\n",
       " 'ColumbiaBankNW',\n",
       " 'CogentCo',\n",
       " 'dormanproducts',\n",
       " 'Korn_Ferry',\n",
       " 'cambrex',\n",
       " 'wattswater',\n",
       " 'Sanderson_Corp',\n",
       " 'knighhtt',\n",
       " 'nwnatural',\n",
       " 'MobileMini',\n",
       " 'JJSnackFoods',\n",
       " 'ViaviSolutions',\n",
       " 'SemtechCorp',\n",
       " 'enerpac',\n",
       " 'MagellanHealth',\n",
       " 'GoTo',\n",
       " 'ProtoLabs',\n",
       " 'ICU_Medical',\n",
       " 'AZZincorporated',\n",
       " 'TesseraTech',\n",
       " 'AdvEnergy',\n",
       " 'boydgaming',\n",
       " 'PREIT',\n",
       " 'OriginalWD40',\n",
       " 'KaiserAlum',\n",
       " 'PwrInt',\n",
       " 'MarriottVAC',\n",
       " 'chemours',\n",
       " 'NETGEAR',\n",
       " 'CintasCorp',\n",
       " 'hmsrecruiting',\n",
       " 'Brady_Corp',\n",
       " 'HaemoneticsCorp',\n",
       " 'asus_inc',\n",
       " 'calwater',\n",
       " 'NWSB',\n",
       " 'PlexusCorp',\n",
       " 'AmedisysInc',\n",
       " 'Tumitravel',\n",
       " 'CousinsREIT',\n",
       " 'Brinks',\n",
       " 'sonicdrivein',\n",
       " 'Synchronoss',\n",
       " 'Old_National',\n",
       " 'SNBSays',\n",
       " 'HPE_Cray',\n",
       " 'expo',\n",
       " 'HubGroup',\n",
       " 'Gentherm',\n",
       " 'IHOP',\n",
       " 'MeritageHomes',\n",
       " 'TopBuild',\n",
       " 'forward_air',\n",
       " 'csg_i',\n",
       " 'WestRock',\n",
       " 'StampsCom',\n",
       " 'ucbankmn',\n",
       " 'FinEngines',\n",
       " 'ingevity',\n",
       " 'HoraceMann',\n",
       " 'childrensplace',\n",
       " 'simmons_bank',\n",
       " 'ExamWorksIS',\n",
       " 'GenescoInc',\n",
       " 'ProgressSW',\n",
       " 'rambusinc',\n",
       " 'EmergentWeGo',\n",
       " 'Popeyes',\n",
       " 'SelectM',\n",
       " 'apogeeglass',\n",
       " 'krispykreme',\n",
       " 'lazboy',\n",
       " 'FranklinWater',\n",
       " 'StillwaterMine',\n",
       " 'SkyWestAirlines',\n",
       " 'AmericanAxle',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_twitter_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data collection is finished and we have all of the companies. Here's what I need to do next:\n",
    "1) Update data for companies who had errors while pulling their data. Should just be the update parameter I've already built in to the function\n",
    "2) Update data for companies who I didn't collect all of their 2022 data (so those who started in Nov and Dec didn't get pulled)\n",
    "3) Add in the summary data I originally pulled into the master file\n",
    "4) Update 2022 data for companies who didn't fully get pulled\n",
    "5) Remove all duplicates from summary for years and ensure those numbers are correct\n",
    "6) Create additional parameter for running new years (i.e. 2023, 2024) for future data pulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293\n"
     ]
    }
   ],
   "source": [
    "# Counts number of data files we have (number of companies we've pulled)\n",
    "import os.path\n",
    "account_type = \"Corporate\"\n",
    "path = \"./\" + account_type + \" Account Data/\"\n",
    "num_files = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = pd.read_excel(\"2022 SP1500 Twitter Handles - Final Deliverable.xlsx\")\n",
    "companies['corp_twitter'] = companies['Corporate Twitter Handle'].str[1:]\n",
    "corp_twitter_list = list(companies[companies['corp_twitter'].notnull()]['corp_twitter'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
